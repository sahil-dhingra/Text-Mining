{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ojSZ5hvYnvV"
   },
   "source": [
    "# 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "colab_type": "code",
    "id": "Z1bVh5k6zxMV",
    "outputId": "f5dac881-4712-417f-9ede-b69343338755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
      "\u001b[K     |████████████████████████████████| 411.5MB 28kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 26.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.28.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 33.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.3)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.0) (46.1.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=668a90b5fc5ab332a8ecaf967ecf5a9b1813073b34df13ce69cb3efe6ac3871f\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow-gpu\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: tensorboard 2.2.1\n",
      "    Uninstalling tensorboard-2.2.1:\n",
      "      Successfully uninstalled tensorboard-2.2.1\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SlW7YHjGz0o5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "krkYS9oyuE7b",
    "outputId": "e27cbd51-ccf8-451c-a681-15cbaeec9d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11U93ts2C0Ts"
   },
   "source": [
    "# 2. Data processing (5 sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "33kkVbAqMzpX",
    "outputId": "1f47c6f9-88e6-4447-d2bd-2808db0b2728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GnLh6Ii9Czmi"
   },
   "outputs": [],
   "source": [
    "exp = pd.read_excel('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/EAC.xlsx')\n",
    "iac = pd.read_excel('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/IAC.xlsx')\n",
    "tac = pd.read_excel('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/TAC.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "724ScgzZFTMp"
   },
   "outputs": [],
   "source": [
    "train_raw = pd.concat([exp[['text','Humor',\t'Sarcastic',\t'Positive',\t'Controversial',\t'Argumentative']], \\\n",
    "           iac[['text','Humor',\t'Sarcastic',\t'Positive',\t'Controversial',\t'Argumentative']], \\\n",
    "           tac[['text','Humor',\t'Sarcastic',\t'Positive',\t'Controversial',\t'Argumentative']]], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9itnys1JRnBn"
   },
   "outputs": [],
   "source": [
    "train_raw['label'] = np.argmax(np.array(train_raw[['Humor',\t'Sarcastic',\t'Positive',\t'Controversial','Argumentative']])==1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JEJQ70-Ze4X"
   },
   "source": [
    "## 2.2 Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x4nCXHBTDGwX",
    "outputId": "5688eaaf-77aa-45fe-87b4-da7425226753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1pC1OjamQ1m8XxdqwMAjGOnwWxhZfmYya\n"
     ]
    }
   ],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "link = \"https://drive.google.com/open?id=1pC1OjamQ1m8XxdqwMAjGOnwWxhZfmYya\"\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('url_to_article.pkl')  \n",
    "df3 = pd.read_pickle('url_to_article.pkl')\n",
    "# Dataset is now stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "np71TvBCDMRP",
    "outputId": "a2f9ef0b-435b-4be1-ed5f-8dcb6e17727b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1onrgx4WblN-H8xwkdNeJ4P88zvs3eYpx\n"
     ]
    }
   ],
   "source": [
    "link = \"https://drive.google.com/open?id=1onrgx4WblN-H8xwkdNeJ4P88zvs3eYpx\"\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('ydata-ynacc-v1_0_expert_annotations.tsv')  \n",
    "df_exp = pd.read_csv('ydata-ynacc-v1_0_expert_annotations.tsv', delimiter=\"\\t\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mK6_kzbvDPUq",
    "outputId": "4c49605b-36e5-444b-bd8a-6ab7c0bb220e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mpQW3XTVHOlM0zYdrOcCdkD95BiV96uz\n"
     ]
    }
   ],
   "source": [
    "link = \"https://drive.google.com/open?id=1mpQW3XTVHOlM0zYdrOcCdkD95BiV96uz\"\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('ydata-ynacc-v1_0_IAC_annotations.tsv')  \n",
    "df_iac = pd.read_csv('ydata-ynacc-v1_0_IAC_annotations.tsv', delimiter=\"\\t\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5FBzBjZVDQta",
    "outputId": "cca383b9-08d3-4300-e9f8-8c897c3ab2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1OpdDWuzFJIGVKf0UqyQi5jMIwkTlwazp\n"
     ]
    }
   ],
   "source": [
    "link = \"https://drive.google.com/open?id=1OpdDWuzFJIGVKf0UqyQi5jMIwkTlwazp\"\n",
    "\n",
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='\n",
    "\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('ydata-ynacc-v1_0_turk_annotations.tsv')\n",
    "df_turk = pd.read_csv('ydata-ynacc-v1_0_turk_annotations.tsv', delimiter=\"\\t\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kov4IhmCDULa"
   },
   "outputs": [],
   "source": [
    "articles = df3[df3.text!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "colab_type": "code",
    "id": "82TK3tDYzpqm",
    "outputId": "28351186-48b1-498c-a656-358d7e5f9caa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdid</th>\n",
       "      <th>commentindex</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>guid</th>\n",
       "      <th>commentid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>thumbs-up</th>\n",
       "      <th>thumbs-down</th>\n",
       "      <th>text</th>\n",
       "      <th>parentid</th>\n",
       "      <th>constructiveclass</th>\n",
       "      <th>sd_agreement</th>\n",
       "      <th>sd_type</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tone</th>\n",
       "      <th>commentagreement</th>\n",
       "      <th>topic</th>\n",
       "      <th>intendedaudience</th>\n",
       "      <th>persuasiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53971</td>\n",
       "      <td>2</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56...</td>\n",
       "      <td>rjrPtwH5oVVuQnEXX3hf</td>\n",
       "      <td>00003n000000000000000000000000-ed2ae6d0-32ac-4...</td>\n",
       "      <td>1459917444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These things happen , Every job has its dangers.</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b...</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disagreement with commenter</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53971</td>\n",
       "      <td>0</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56...</td>\n",
       "      <td>VaW6HEsuOFUAIBqjw1k~</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b...</td>\n",
       "      <td>1459879464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sad to hear such a bad thing. Very dangerous j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>mixed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Broadcast message / general audience</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53971</td>\n",
       "      <td>1</td>\n",
       "      <td>Disneyland Worker Found Dead in Haunted Mansion</td>\n",
       "      <td>http://www.cosmopolitan.com/lifestyle/news/a56...</td>\n",
       "      <td>uwQePj970KaMZuW3~9Q9</td>\n",
       "      <td>00002n000000000000000000000000-1c30b878-b717-4...</td>\n",
       "      <td>1459881644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes..because too many houses in EU look like t...</td>\n",
       "      <td>1459879464596-a3771c05-fd2e-4f44-a26a-23baec3b...</td>\n",
       "      <td>Constructive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive/respectful</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Informative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135929</td>\n",
       "      <td>0</td>\n",
       "      <td>This Old Navy Ad Featuring an Interracial Fami...</td>\n",
       "      <td>http://mic.com/articles/142323/this-old-navy-a...</td>\n",
       "      <td>fixyWJivQjEQtPLLVXsu</td>\n",
       "      <td>1462203719963-3eeffb02-faae-4b51-9174-704c57e6...</td>\n",
       "      <td>1462203719</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I am frankly quite SICK of the phrase \"shoved ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not constructive</td>\n",
       "      <td>Agreement throughout</td>\n",
       "      <td>Off-topic/digression</td>\n",
       "      <td>negative</td>\n",
       "      <td>Mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Broadcast message / general audience</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135929</td>\n",
       "      <td>1</td>\n",
       "      <td>This Old Navy Ad Featuring an Interracial Fami...</td>\n",
       "      <td>http://mic.com/articles/142323/this-old-navy-a...</td>\n",
       "      <td>_TDnK715vO5y0OzZz_n4</td>\n",
       "      <td>00002I000000000000000000000000-7ef2ac58-bd84-4...</td>\n",
       "      <td>1462204643</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ya, I always wonder why the conservatives are ...</td>\n",
       "      <td>1462203719963-3eeffb02-faae-4b51-9174-704c57e6...</td>\n",
       "      <td>Not constructive</td>\n",
       "      <td>Agreement throughout</td>\n",
       "      <td>Off-topic/digression</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Agreement with commenter</td>\n",
       "      <td>Off-topic with article</td>\n",
       "      <td>Reply to a specific commenter</td>\n",
       "      <td>Not persuasive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sdid  commentindex  ...                      intendedaudience  persuasiveness\n",
       "0   53971             2  ...         Reply to a specific commenter  Not persuasive\n",
       "1   53971             0  ...  Broadcast message / general audience  Not persuasive\n",
       "2   53971             1  ...         Reply to a specific commenter  Not persuasive\n",
       "3  135929             0  ...  Broadcast message / general audience      Persuasive\n",
       "4  135929             1  ...         Reply to a specific commenter  Not persuasive\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = df_exp\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S6kyJH661det",
    "outputId": "c197a135-e8ac-49b4-fd82-64014e2863b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23383, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Hr1v_VoZqws"
   },
   "source": [
    "## 2.3 Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbxSBv8m6XaR"
   },
   "source": [
    "Select non null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wmb8-t51zx0n",
    "outputId": "48d67153-afc9-4528-ec36-dbfee2f217e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23383, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[train_raw.text.notnull()]\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "pAMdnQBv1qlC",
    "outputId": "3b722bd5-186c-4fef-caa3-28fdbf0e520b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ad041bcf8>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw.text.apply(lambda x: len(x.split())).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "eGyH4kwB0TH6",
    "outputId": "6f655411-1fc5-4346-bd92-b400252b6ca8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdid</th>\n",
       "      <th>commentindex</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>thumbs-up</th>\n",
       "      <th>thumbs-down</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23383.000000</td>\n",
       "      <td>23383.000000</td>\n",
       "      <td>2.338300e+04</td>\n",
       "      <td>16602.000000</td>\n",
       "      <td>14778.000000</td>\n",
       "      <td>23383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80398.647522</td>\n",
       "      <td>3.373049</td>\n",
       "      <td>1.461384e+09</td>\n",
       "      <td>6.985243</td>\n",
       "      <td>3.968873</td>\n",
       "      <td>45.476372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50722.026622</td>\n",
       "      <td>2.877231</td>\n",
       "      <td>3.117790e+06</td>\n",
       "      <td>14.963799</td>\n",
       "      <td>4.831545</td>\n",
       "      <td>75.455620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.418834e+09</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39565.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.460433e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76889.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.461212e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118961.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.461972e+09</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215878.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.472131e+09</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2440.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sdid  commentindex  ...   thumbs-down       len_txt\n",
       "count   23383.000000  23383.000000  ...  14778.000000  23383.000000\n",
       "mean    80398.647522      3.373049  ...      3.968873     45.476372\n",
       "std     50722.026622      2.877231  ...      4.831545     75.455620\n",
       "min        27.000000      0.000000  ...      1.000000      1.000000\n",
       "25%     39565.000000      1.000000  ...      1.000000     12.000000\n",
       "50%     76889.000000      3.000000  ...      2.000000     25.000000\n",
       "75%    118961.000000      5.000000  ...      5.000000     53.000000\n",
       "max    215878.000000     15.000000  ...     91.000000   2440.000000\n",
       "\n",
       "[8 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['len_txt'] =train_raw.text.apply(lambda x: len(x.split()))\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LqFgGC_TkvyA",
    "outputId": "6181f0c6-b241-4211-df48-f0a53efe701a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23383, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SumN633drVVO"
   },
   "source": [
    "Select only the row with number of words greater than 250:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "maZQzkqv0iFa",
    "outputId": "e4251eb2-1b6d-4997-dace-f7b1670188e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_raw = train_raw[train_raw.len_txt >249]\n",
    "#train_raw.shape\n",
    "ind = train_raw.len_txt>512\n",
    "ind.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "WzYJ1SYn0uE6",
    "outputId": "bececfb8-28b3-4801-b173-69ce6d65286e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These things happen , Every job has its dangers.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sad to hear such a bad thing. Very dangerous j...</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes..because too many houses in EU look like t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am frankly quite SICK of the phrase \"shoved ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ya, I always wonder why the conservatives are ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0   These things happen , Every job has its dangers.  negative\n",
       "1  Sad to hear such a bad thing. Very dangerous j...     mixed\n",
       "2  Yes..because too many houses in EU look like t...   neutral\n",
       "3  I am frankly quite SICK of the phrase \"shoved ...  negative\n",
       "4  Ya, I always wonder why the conservatives are ...   neutral"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[['text', 'sentiment']]\n",
    "train_raw.reset_index(inplace=True, drop=True)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beKGErd96q9p"
   },
   "source": [
    "Group similar products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nluIhTc-KAKe"
   },
   "outputs": [],
   "source": [
    "train_raw['label'] = train_raw['sentiment'].astype('str')\n",
    "train_raw['label'][train_raw['label']=='neutral'] = 'positive'\n",
    "train_raw = train_raw[train_raw['label']!='nan']\n",
    "train_raw = train_raw.drop(columns = 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "ISkKV5RX344m",
    "outputId": "ce94296f-07d4-424f-856b-6d18a963ba6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5acf9c0160>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw['label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qKwPN_5iUVxx"
   },
   "outputs": [],
   "source": [
    "train_raw = train_raw[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "JFckqSM_4Pvr",
    "outputId": "ec4a1f68-11ee-44d2-b090-b84376094b90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These things happen , Every job has its dangers.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sad to hear such a bad thing. Very dangerous j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes..because too many houses in EU look like t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am frankly quite SICK of the phrase \"shoved ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ya, I always wonder why the conservatives are ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   These things happen , Every job has its dangers.      1\n",
       "1  Sad to hear such a bad thing. Very dangerous j...      0\n",
       "2  Yes..because too many houses in EU look like t...      2\n",
       "3  I am frankly quite SICK of the phrase \"shoved ...      1\n",
       "4  Ya, I always wonder why the conservatives are ...      2"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VvAEbfcK40vP",
    "outputId": "440e1985-a1f8-44db-c36c-c1cdfc8bce11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_raw['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vjTcB2IElYK-"
   },
   "outputs": [],
   "source": [
    "train = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "_KSdpULo4vBM",
    "outputId": "1ffd1cf7-2044-4e76-bc3c-c03e17254d66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>I agree. No one has the right to hide that sor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Speaking of Aliens... I wonder where they go t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>Only 3 billion in new shares? Pumped up stock ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>His appeals to a certain demographic.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22589</th>\n",
       "      <td>Globalization is a great idea, theoretically. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "4582   I agree. No one has the right to hide that sor...      2\n",
       "1534   Speaking of Aliens... I wonder where they go t...      2\n",
       "6142   Only 3 billion in new shares? Pumped up stock ...      1\n",
       "10236              His appeals to a certain demographic.      2\n",
       "22589  Globalization is a great idea, theoretically. ...      1"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reindex(np.random.permutation(train.index))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJaaGqEC61Tw"
   },
   "source": [
    "Clean the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lFLkBvrnyKnt"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "    text = re.sub(\"'\", \"\",text)\n",
    "    text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "C4yHuGEayROw",
    "outputId": "eada39af-08b7-44af-d5cb-bd39dd84d6d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>I agree No one has the right to hide that sort...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Speaking of Aliens I wonder where they go to f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>Only 3 billion in new shares Pumped up stock o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>His appeals to a certain demographic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22589</th>\n",
       "      <td>Globalization is a great idea theoretically Co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "4582   I agree No one has the right to hide that sort...      2\n",
       "1534   Speaking of Aliens I wonder where they go to f...      2\n",
       "6142   Only 3 billion in new shares Pumped up stock o...      1\n",
       "10236              His appeals to a certain demographic       2\n",
       "22589  Globalization is a great idea theoretically Co...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']  = train.text.apply(clean_txt)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "S3EJew8g5cUK",
    "outputId": "6e96d3ed-49bd-4547-d52b-66ef4042e1bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>They look like the typical liberals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18266</th>\n",
       "      <td>So his point is that there are loving interrac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>Ernest you is correct If the attackers were wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20295</th>\n",
       "      <td>please take your medicine then read your ignor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12576</th>\n",
       "      <td>funny im saying the same thing about PS4 right...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2387                They look like the typical liberals       1\n",
       "18266  So his point is that there are loving interrac...      0\n",
       "7773   Ernest you is correct If the attackers were wh...      0\n",
       "20295  please take your medicine then read your ignor...      1\n",
       "12576  funny im saying the same thing about PS4 right...      0"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ziIsgHqrz0n6",
    "outputId": "55e33174-22c2-4aae-8f02-0ae6ddae0d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4611, 2), (18444, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "TGq2lzLG59SC",
    "outputId": "d677b85d-ec52-4b66-e2e0-f40acb5b0f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\r",
      "\u001b[K     |████▉                           | 10kB 21.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 40kB 1.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 51kB 1.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 61kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "source": [
    "#Installing BERT module\n",
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "zTcMyKKl6DdA",
    "outputId": "c753962d-e28b-4b82-d299-b5d585bfef68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ej8QOozZbEva"
   },
   "source": [
    "# Setting The Output Directory for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NNPhIMrr6ra9",
    "outputId": "32145b09-004d-4fed-c0a0-8bb995a2f691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: /bert_news_category *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = '/bert_news_category'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "    try:\n",
    "        tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "0YGONt0p60Ay",
    "outputId": "83fa47b6-7769-490c-dad8-0fcd091fe7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (18444, 2)\n",
      "Validation Set Shape : (4611, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "# print(\"Test Set Shape :\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s6NYKx4P7N66",
    "outputId": "9688e97a-4586-4aee-a19f-703c8ef500ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SABuVQdlC4Tu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "LYaNm0YzC3kj",
    "outputId": "7f40600e-5d40-4b3e-b4a5-610519369baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18389, 2)\n",
      "(55, 2)\n",
      "(4600, 2)\n",
      "(11, 2)\n"
     ]
    }
   ],
   "source": [
    "train_lo = train[~train.index.isin(ind[ind==True].index)]\n",
    "train_hi = train[train.index.isin(ind[ind==True].index)]\n",
    "val_lo = val[~val.index.isin(ind[ind==True].index)]\n",
    "val_hi = val[val.index.isin(ind[ind==True].index)]\n",
    "print(train_lo.shape)\n",
    "print(train_hi.shape)\n",
    "print(val_lo.shape)\n",
    "print(val_hi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOSEd24bbiUq"
   },
   "source": [
    "# Splitting the Data into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ausf5AlOkPCH"
   },
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "E-u6mDkbLpTY",
    "outputId": "069d0fe6-a7a9-475d-d86e-7a8fa0e75ea1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>I used to think the RocknRoll Hall of Fame mea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I used to think the RocknRoll Hall of Fame me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>No one has ever died from a Marijuana overdose...</td>\n",
       "      <td>0</td>\n",
       "      <td>[No one has ever died from a Marijuana overdos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>It doesnt matter if someone has one tattoo or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[It doesnt matter if someone has one tattoo or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>USERNAME I suspect you fear the government an...</td>\n",
       "      <td>1</td>\n",
       "      <td>[USERNAME I suspect you fear the government an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>AIRHEAD MOOSE HUNTING Palin SUING LMBO Any Jud...</td>\n",
       "      <td>1</td>\n",
       "      <td>[AIRHEAD MOOSE HUNTING Palin SUING LMBO Any Ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  ...                                         text_split\n",
       "14693  I used to think the RocknRoll Hall of Fame mea...  ...  [I used to think the RocknRoll Hall of Fame me...\n",
       "920    No one has ever died from a Marijuana overdose...  ...  [No one has ever died from a Marijuana overdos...\n",
       "11581  It doesnt matter if someone has one tattoo or ...  ...  [It doesnt matter if someone has one tattoo or...\n",
       "679     USERNAME I suspect you fear the government an...  ...  [USERNAME I suspect you fear the government an...\n",
       "13698  AIRHEAD MOOSE HUNTING Palin SUING LMBO Any Jud...  ...  [AIRHEAD MOOSE HUNTING Palin SUING LMBO Any Ju...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hi['text_split'] = train_hi[DATA_COLUMN].apply(get_split)\n",
    "train_hi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "-zrlehCFUplB",
    "outputId": "63103e48-71da-4e21-9372-1776f0f9b65e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>Why are Blacks hated part 1 African Americans ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Why are Blacks hated part 1 African Americans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>Did you explain the following to him because I...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Did you explain the following to him because ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ...                                         text_split\n",
       "7037  Why are Blacks hated part 1 African Americans ...  ...  [Why are Blacks hated part 1 African Americans...\n",
       "8894  Did you explain the following to him because I...  ...  [Did you explain the following to him because ...\n",
       "\n",
       "[2 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hi['text_split'] = val_hi[DATA_COLUMN].apply(get_split)\n",
    "val_hi.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5_zMerj1VGaM",
    "outputId": "1b82aaa3-a2ad-4436-9c26-fe1e1d847c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 327, 327)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train_hi.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rBrXEaxHVNG4",
    "outputId": "80b06317-2bd4-4d03-b9a3-92c2e03d2bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55, 55)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val_hi.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hu5Sx8Rm0bAj"
   },
   "source": [
    "The final dataset for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "mojRk8kWVVB4",
    "outputId": "cefad841-23dd-4e56-c646-33b94d8dd1bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I used to think the RocknRoll Hall of Fame mea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitely two of my favs ToNs lead singer Pet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word Ask Eric Clapton who personally and openl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No one has ever died from a Marijuana overdose...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they destroy on pot crimes that would go away ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I used to think the RocknRoll Hall of Fame mea...      1\n",
       "1  Definitely two of my favs ToNs lead singer Pet...      1\n",
       "2  word Ask Eric Clapton who personally and openl...      1\n",
       "3  No one has ever died from a Marijuana overdose...      0\n",
       "4  they destroy on pot crimes that would go away ...      0"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "k_I-ZbSKVmrZ",
    "outputId": "3a454dd3-48f7-499f-baf4-7ad0587c8aec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why are Blacks hated part 1 African Americans ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what it should be according to their populatio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Americans account for 32 of Other Assault Crim...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>times compared to what it should be according ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have a 0 52 ratio African Americans account fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Why are Blacks hated part 1 African Americans ...      2\n",
       "1  what it should be according to their populatio...      2\n",
       "2  Americans account for 32 of Other Assault Crim...      2\n",
       "3  times compared to what it should be according ...      2\n",
       "4  have a 0 52 ratio African Americans account fo...      2"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tPchJKvQBzCI"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_lo], axis=0).reset_index(drop=True)\n",
    "val_df = pd.concat([val_df, val_lo], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "IdYoNhyOMhH7",
    "outputId": "0085e28a-c1c9-43fe-bd53-dd4c456a51b9"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2753de023744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/train_df5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/val_df5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/train_df5.csv'"
     ]
    }
   ],
   "source": [
    "train_df.to_csv('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/train_df5.csv')\n",
    "val_df.to_csv('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/val_df5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "og08g7DScPtK"
   },
   "source": [
    "# BERT: Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PWVomvm7TV5"
   },
   "source": [
    "Process the data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e-_zLSnh7evE"
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "UOq7ETNe7zGJ",
    "outputId": "0f641839-5e4e-4cc4-f876-0b43aaa29781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <bert.run_classifier.InputExample object at 0x...\n",
       "1        <bert.run_classifier.InputExample object at 0x...\n",
       "2        <bert.run_classifier.InputExample object at 0x...\n",
       "3        <bert.run_classifier.InputExample object at 0x...\n",
       "4        <bert.run_classifier.InputExample object at 0x...\n",
       "                               ...                        \n",
       "18711    <bert.run_classifier.InputExample object at 0x...\n",
       "18712    <bert.run_classifier.InputExample object at 0x...\n",
       "18713    <bert.run_classifier.InputExample object at 0x...\n",
       "18714    <bert.run_classifier.InputExample object at 0x...\n",
       "18715    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 18716, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "d0E8U0OQ8VW6",
    "outputId": "46a3a41d-5930-4be6-93c0-b959c3f8d584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  I used to think the RocknRoll Hall of Fame meant royalty until I discovered WHO started it and why Im surprised someone didnt beat Jann Werner to it Gotta give him credit for pushing forth HIS pet project but in truth its a personal club HIS club The people have very little to do with the selection I agree with quite a few on your list No 1 being Love Arthur Lee was a visionary Fire up the song Seven and Seven and see if you can sit still Anytime I want a caffeine jolt this is the song that does it I can live with Journey Steve Perrys voice is a classic I agree about the Cure But add another C band the Cult Ian Astburys is as powerful as any singer whoever stood behind a mic Metal bands Type O Negative and Rammstein Two of the finest ever Definitely two of my favs ToNs lead singer Peter Steele had a persona about him that still resonates five years after his death Rammstein is simply riveting to watch Theres no opera ever written that can create the powerful emotions than these guys produce with their brand of music and\n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoIt5AHadACM"
   },
   "source": [
    "# BERT: Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "W4PZ8ogj8ae2",
    "outputId": "b203896f-1383-448c-e5bf-fffc3f90248e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qS_ybJmv8lye",
    "outputId": "1f25c200-45be-4a12-c868-22e855163e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "O6OqoZjv8r27",
    "outputId": "68df1bb3-472f-4530-afb2-dcee8cd3aba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'used', 'to', 'think', 'the', 'rock', '##nr', '##oll', 'hall', 'of', 'fame', 'meant', 'royalty', 'until', 'i', 'discovered', 'who', 'started', 'it', 'and', 'why', 'im', 'surprised', 'someone', 'didn', '##t', 'beat', 'jan', '##n', 'werner', 'to', 'it', 'gotta', 'give', 'him', 'credit', 'for', 'pushing', 'forth', 'his', 'pet', 'project', 'but', 'in', 'truth', 'its', 'a', 'personal', 'club', 'his', 'club', 'the', 'people', 'have', 'very', 'little', 'to', 'do', 'with', 'the', 'selection', 'i', 'agree', 'with', 'quite', 'a', 'few', 'on', 'your', 'list', 'no', '1', 'being', 'love', 'arthur', 'lee', 'was', 'a', 'visionary', 'fire', 'up', 'the', 'song', 'seven', 'and', 'seven', 'and', 'see', 'if', 'you', 'can', 'sit', 'still', 'anytime', 'i', 'want', 'a', 'caf', '##fe', '##ine', 'jolt', 'this', 'is', 'the', 'song', 'that', 'does', 'it', 'i', 'can', 'live', 'with', 'journey', 'steve', 'perry', '##s', 'voice', 'is', 'a', 'classic', 'i', 'agree', 'about', 'the', 'cure', 'but', 'add', 'another', 'c', 'band', 'the', 'cult', 'ian', 'as', '##t', '##bury', '##s', 'is', 'as', 'powerful', 'as', 'any', 'singer', 'whoever', 'stood', 'behind', 'a', 'mic', 'metal', 'bands', 'type', 'o', 'negative', 'and', 'ram', '##ms', '##tein', 'two', 'of', 'the', 'finest', 'ever', 'definitely', 'two', 'of', 'my', 'fa', '##vs', 'tons', 'lead', 'singer', 'peter', 'steele', 'had', 'a', 'persona', 'about', 'him', 'that', 'still', 'res', '##onate', '##s', 'five', 'years', 'after', 'his', 'death', 'ram', '##ms', '##tein', 'is', 'simply', 'ri', '##vet', '##ing', 'to', 'watch', 'there', '##s', 'no', 'opera', 'ever', 'written', 'that', 'can', 'create', 'the', 'powerful', 'emotions', 'than', 'these', 'guys', 'produce', 'with', 'their', 'brand', 'of', 'music', 'and']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q87k_orF8vpz"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G_LBy-yy-GSU",
    "outputId": "679ecf23-8683-4f9b-e1c2-c4c78aedba50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 18716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 18716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i used to think the rock ##nr ##oll hall of fame meant royalty until i discovered who started it and why im surprised someone didn ##t beat jan ##n werner to it gotta give him credit for pushing forth his pet project but in truth its a personal club his club the people have very little to do with the selection i agree with quite a few on your list no 1 being love arthur lee was a visionary fire up the song seven and seven and see if you can sit still anytime i want a caf ##fe ##ine jolt this is the song that does it i can live with journey steve perry ##s voice is a classic i agree about the cure but add another c band the cult ian as ##t ##bury ##s is as powerful as any singer whoever stood behind a mic metal bands type o negative and ram ##ms ##tein two of the finest ever definitely two of my fa ##vs tons lead singer peter steele had a persona about him that still res ##onate ##s five years after his death ram ##ms ##tein is simply ri ##vet ##ing to watch there ##s no opera ever written that can create the powerful emotions than these guys produce with their brand of music and [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i used to think the rock ##nr ##oll hall of fame meant royalty until i discovered who started it and why im surprised someone didn ##t beat jan ##n werner to it gotta give him credit for pushing forth his pet project but in truth its a personal club his club the people have very little to do with the selection i agree with quite a few on your list no 1 being love arthur lee was a visionary fire up the song seven and seven and see if you can sit still anytime i want a caf ##fe ##ine jolt this is the song that does it i can live with journey steve perry ##s voice is a classic i agree about the cure but add another c band the cult ian as ##t ##bury ##s is as powerful as any singer whoever stood behind a mic metal bands type o negative and ram ##ms ##tein two of the finest ever definitely two of my fa ##vs tons lead singer peter steele had a persona about him that still res ##onate ##s five years after his death ram ##ms ##tein is simply ri ##vet ##ing to watch there ##s no opera ever written that can create the powerful emotions than these guys produce with their brand of music and [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2109 2000 2228 1996 2600 16118 14511 2534 1997 4476 3214 16664 2127 1045 3603 2040 2318 2009 1998 2339 10047 4527 2619 2134 2102 3786 5553 2078 14121 2000 2009 10657 2507 2032 4923 2005 6183 5743 2010 9004 2622 2021 1999 3606 2049 1037 3167 2252 2010 2252 1996 2111 2031 2200 2210 2000 2079 2007 1996 4989 1045 5993 2007 3243 1037 2261 2006 2115 2862 2053 1015 2108 2293 4300 3389 2001 1037 28036 2543 2039 1996 2299 2698 1998 2698 1998 2156 2065 2017 2064 4133 2145 15933 1045 2215 1037 24689 7959 3170 22538 2023 2003 1996 2299 2008 2515 2009 1045 2064 2444 2007 4990 3889 6890 2015 2376 2003 1037 4438 1045 5993 2055 1996 9526 2021 5587 2178 1039 2316 1996 8754 4775 2004 2102 4917 2015 2003 2004 3928 2004 2151 3220 9444 2768 2369 1037 23025 3384 4996 2828 1051 4997 1998 8223 5244 9589 2048 1997 1996 10418 2412 5791 2048 1997 2026 6904 15088 6197 2599 3220 2848 12872 2018 1037 16115 2055 2032 2008 2145 24501 21149 2015 2274 2086 2044 2010 2331 8223 5244 9589 2003 3432 15544 19510 2075 2000 3422 2045 2015 2053 3850 2412 2517 2008 2064 3443 1996 3928 6699 2084 2122 4364 3965 2007 2037 4435 1997 2189 1998 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2109 2000 2228 1996 2600 16118 14511 2534 1997 4476 3214 16664 2127 1045 3603 2040 2318 2009 1998 2339 10047 4527 2619 2134 2102 3786 5553 2078 14121 2000 2009 10657 2507 2032 4923 2005 6183 5743 2010 9004 2622 2021 1999 3606 2049 1037 3167 2252 2010 2252 1996 2111 2031 2200 2210 2000 2079 2007 1996 4989 1045 5993 2007 3243 1037 2261 2006 2115 2862 2053 1015 2108 2293 4300 3389 2001 1037 28036 2543 2039 1996 2299 2698 1998 2698 1998 2156 2065 2017 2064 4133 2145 15933 1045 2215 1037 24689 7959 3170 22538 2023 2003 1996 2299 2008 2515 2009 1045 2064 2444 2007 4990 3889 6890 2015 2376 2003 1037 4438 1045 5993 2055 1996 9526 2021 5587 2178 1039 2316 1996 8754 4775 2004 2102 4917 2015 2003 2004 3928 2004 2151 3220 9444 2768 2369 1037 23025 3384 4996 2828 1051 4997 1998 8223 5244 9589 2048 1997 1996 10418 2412 5791 2048 1997 2026 6904 15088 6197 2599 3220 2848 12872 2018 1037 16115 2055 2032 2008 2145 24501 21149 2015 2274 2086 2044 2010 2331 8223 5244 9589 2003 3432 15544 19510 2075 2000 3422 2045 2015 2053 3850 2412 2517 2008 2064 3443 1996 3928 6699 2084 2122 4364 3965 2007 2037 4435 1997 2189 1998 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] definitely two of my fa ##vs tons lead singer peter steele had a persona about him that still res ##onate ##s five years after his death ram ##ms ##tein is simply ri ##vet ##ing to watch there ##s no opera ever written that can create the powerful emotions than these guys produce with their brand of music and show ##manship and what about steppe ##n ##wo ##lf the term heavy metal thunder came from a mars bonfire penned lyric in the song born to be wild over four decades john kay has been true to the roots of rock he and the band are still out there putting forth the classics never seen a bad show ever as for your suggestions of ba ##uh ##aus and sisters of mercy definitely id add ne ##na from germany alongside kraft ##werk speaking of sf bands hot tuna produced just as much excitement as jefferson airplane jo ##rma ka ##uk ##onne ##n plays guitar like few others on the planet don ##t take my word ask eric clapton who personally and openly said so the 80s alone has enough overlooked and probably never elected bands that would fill up a wing of the ho ##f psychedelic fur ##s were known primarily for pretty in pink but richard butler ##s voice and lyrics were stronger than current ind ##uc ##tee [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] definitely two of my fa ##vs tons lead singer peter steele had a persona about him that still res ##onate ##s five years after his death ram ##ms ##tein is simply ri ##vet ##ing to watch there ##s no opera ever written that can create the powerful emotions than these guys produce with their brand of music and show ##manship and what about steppe ##n ##wo ##lf the term heavy metal thunder came from a mars bonfire penned lyric in the song born to be wild over four decades john kay has been true to the roots of rock he and the band are still out there putting forth the classics never seen a bad show ever as for your suggestions of ba ##uh ##aus and sisters of mercy definitely id add ne ##na from germany alongside kraft ##werk speaking of sf bands hot tuna produced just as much excitement as jefferson airplane jo ##rma ka ##uk ##onne ##n plays guitar like few others on the planet don ##t take my word ask eric clapton who personally and openly said so the 80s alone has enough overlooked and probably never elected bands that would fill up a wing of the ho ##f psychedelic fur ##s were known primarily for pretty in pink but richard butler ##s voice and lyrics were stronger than current ind ##uc ##tee [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5791 2048 1997 2026 6904 15088 6197 2599 3220 2848 12872 2018 1037 16115 2055 2032 2008 2145 24501 21149 2015 2274 2086 2044 2010 2331 8223 5244 9589 2003 3432 15544 19510 2075 2000 3422 2045 2015 2053 3850 2412 2517 2008 2064 3443 1996 3928 6699 2084 2122 4364 3965 2007 2037 4435 1997 2189 1998 2265 21530 1998 2054 2055 29096 2078 12155 10270 1996 2744 3082 3384 8505 2234 2013 1037 7733 28698 17430 13677 1999 1996 2299 2141 2000 2022 3748 2058 2176 5109 2198 10905 2038 2042 2995 2000 1996 6147 1997 2600 2002 1998 1996 2316 2024 2145 2041 2045 5128 5743 1996 10002 2196 2464 1037 2919 2265 2412 2004 2005 2115 15690 1997 8670 27225 20559 1998 5208 1997 8673 5791 8909 5587 11265 2532 2013 2762 4077 26680 29548 4092 1997 16420 4996 2980 24799 2550 2074 2004 2172 8277 2004 7625 13297 8183 17830 10556 6968 18256 2078 3248 2858 2066 2261 2500 2006 1996 4774 2123 2102 2202 2026 2773 3198 4388 24705 2040 7714 1998 10132 2056 2061 1996 16002 2894 2038 2438 17092 1998 2763 2196 2700 4996 2008 2052 6039 2039 1037 3358 1997 1996 7570 2546 18147 6519 2015 2020 2124 3952 2005 3492 1999 5061 2021 2957 7055 2015 2376 1998 4581 2020 6428 2084 2783 27427 14194 17389 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5791 2048 1997 2026 6904 15088 6197 2599 3220 2848 12872 2018 1037 16115 2055 2032 2008 2145 24501 21149 2015 2274 2086 2044 2010 2331 8223 5244 9589 2003 3432 15544 19510 2075 2000 3422 2045 2015 2053 3850 2412 2517 2008 2064 3443 1996 3928 6699 2084 2122 4364 3965 2007 2037 4435 1997 2189 1998 2265 21530 1998 2054 2055 29096 2078 12155 10270 1996 2744 3082 3384 8505 2234 2013 1037 7733 28698 17430 13677 1999 1996 2299 2141 2000 2022 3748 2058 2176 5109 2198 10905 2038 2042 2995 2000 1996 6147 1997 2600 2002 1998 1996 2316 2024 2145 2041 2045 5128 5743 1996 10002 2196 2464 1037 2919 2265 2412 2004 2005 2115 15690 1997 8670 27225 20559 1998 5208 1997 8673 5791 8909 5587 11265 2532 2013 2762 4077 26680 29548 4092 1997 16420 4996 2980 24799 2550 2074 2004 2172 8277 2004 7625 13297 8183 17830 10556 6968 18256 2078 3248 2858 2066 2261 2500 2006 1996 4774 2123 2102 2202 2026 2773 3198 4388 24705 2040 7714 1998 10132 2056 2061 1996 16002 2894 2038 2438 17092 1998 2763 2196 2700 4996 2008 2052 6039 2039 1037 3358 1997 1996 7570 2546 18147 6519 2015 2020 2124 3952 2005 3492 1999 5061 2021 2957 7055 2015 2376 1998 4581 2020 6428 2084 2783 27427 14194 17389 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] word ask eric clapton who personally and openly said so the 80s alone has enough overlooked and probably never elected bands that would fill up a wing of the ho ##f psychedelic fur ##s were known primarily for pretty in pink but richard butler ##s voice and lyrics were stronger than current ind ##uc ##tee joan jett how in hell did she make it in one hit one cover and that ##s it what body of work over 25 y ##rs the bang ##les and the go go ##s over madonna any day they could perform and speaking of powerful female voices i def ##y anyone to overlook concrete blonde ##s john ##ette ne ##pol ##itan ##o listen to joey or leonard cohen ##s everybody knows she covers and then tell me there ##s a better female singer anywhere i have far too many to list and probably leaving out more than id like to list but i agree with those who def ##y the sainte ##d cleveland based hall but inducted in nyc venue jan ##n werner and his hen ##ch ##men call bon ##af ##ide recently ax ##l rose the original singer of guns ##nr ##oses declined the op to go in if it wasn ##t for those already in id say the whole venue is a far ##ce one guy and his buddies beat the others [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] word ask eric clapton who personally and openly said so the 80s alone has enough overlooked and probably never elected bands that would fill up a wing of the ho ##f psychedelic fur ##s were known primarily for pretty in pink but richard butler ##s voice and lyrics were stronger than current ind ##uc ##tee joan jett how in hell did she make it in one hit one cover and that ##s it what body of work over 25 y ##rs the bang ##les and the go go ##s over madonna any day they could perform and speaking of powerful female voices i def ##y anyone to overlook concrete blonde ##s john ##ette ne ##pol ##itan ##o listen to joey or leonard cohen ##s everybody knows she covers and then tell me there ##s a better female singer anywhere i have far too many to list and probably leaving out more than id like to list but i agree with those who def ##y the sainte ##d cleveland based hall but inducted in nyc venue jan ##n werner and his hen ##ch ##men call bon ##af ##ide recently ax ##l rose the original singer of guns ##nr ##oses declined the op to go in if it wasn ##t for those already in id say the whole venue is a far ##ce one guy and his buddies beat the others [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2773 3198 4388 24705 2040 7714 1998 10132 2056 2061 1996 16002 2894 2038 2438 17092 1998 2763 2196 2700 4996 2008 2052 6039 2039 1037 3358 1997 1996 7570 2546 18147 6519 2015 2020 2124 3952 2005 3492 1999 5061 2021 2957 7055 2015 2376 1998 4581 2020 6428 2084 2783 27427 14194 17389 7437 22962 2129 1999 3109 2106 2016 2191 2009 1999 2028 2718 2028 3104 1998 2008 2015 2009 2054 2303 1997 2147 2058 2423 1061 2869 1996 9748 4244 1998 1996 2175 2175 2015 2058 11284 2151 2154 2027 2071 4685 1998 4092 1997 3928 2931 5755 1045 13366 2100 3087 2000 27590 5509 9081 2015 2198 7585 11265 18155 25451 2080 4952 2000 9558 2030 7723 9946 2015 7955 4282 2016 4472 1998 2059 2425 2033 2045 2015 1037 2488 2931 3220 5973 1045 2031 2521 2205 2116 2000 2862 1998 2763 2975 2041 2062 2084 8909 2066 2000 2862 2021 1045 5993 2007 2216 2040 13366 2100 1996 16947 2094 6044 2241 2534 2021 8120 1999 16392 6891 5553 2078 14121 1998 2010 21863 2818 3549 2655 14753 10354 5178 3728 22260 2140 3123 1996 2434 3220 1997 4409 16118 27465 6430 1996 6728 2000 2175 1999 2065 2009 2347 2102 2005 2216 2525 1999 8909 2360 1996 2878 6891 2003 1037 2521 3401 2028 3124 1998 2010 24115 3786 1996 2500 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2773 3198 4388 24705 2040 7714 1998 10132 2056 2061 1996 16002 2894 2038 2438 17092 1998 2763 2196 2700 4996 2008 2052 6039 2039 1037 3358 1997 1996 7570 2546 18147 6519 2015 2020 2124 3952 2005 3492 1999 5061 2021 2957 7055 2015 2376 1998 4581 2020 6428 2084 2783 27427 14194 17389 7437 22962 2129 1999 3109 2106 2016 2191 2009 1999 2028 2718 2028 3104 1998 2008 2015 2009 2054 2303 1997 2147 2058 2423 1061 2869 1996 9748 4244 1998 1996 2175 2175 2015 2058 11284 2151 2154 2027 2071 4685 1998 4092 1997 3928 2931 5755 1045 13366 2100 3087 2000 27590 5509 9081 2015 2198 7585 11265 18155 25451 2080 4952 2000 9558 2030 7723 9946 2015 7955 4282 2016 4472 1998 2059 2425 2033 2045 2015 1037 2488 2931 3220 5973 1045 2031 2521 2205 2116 2000 2862 1998 2763 2975 2041 2062 2084 8909 2066 2000 2862 2021 1045 5993 2007 2216 2040 13366 2100 1996 16947 2094 6044 2241 2534 2021 8120 1999 16392 6891 5553 2078 14121 1998 2010 21863 2818 3549 2655 14753 10354 5178 3728 22260 2140 3123 1996 2434 3220 1997 4409 16118 27465 6430 1996 6728 2000 2175 1999 2065 2009 2347 2102 2005 2216 2525 1999 8909 2360 1996 2878 6891 2003 1037 2521 3401 2028 3124 1998 2010 24115 3786 1996 2500 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no one has ever died from a marijuana overdose you need at least 300 times the into ##xi ##cating amount to die so why are there any guidelines for marijuana other than it should be treated like alcohol with alcohol no one registers no one is tracked no one is limited so why the ongoing freak out on marijuana we need to stop acting like its some kind of heavy criminal drug thing o we should really ask ourselves what the heck are people we have let be in charge trying to stop by not legal ##izing marijuana or limiting marijuana and putting out propaganda and sensation ##ali ##zed false police reports o are they part of the dea are they part of the police are they part of the judicial system because all of those people i just mentioned are very biased because they are protecting their jobs that oversees the millions of lives they destroy on pot crimes that would go away if pot was legal ##ized o o or are these fighters of legal ##ization so prop ##aga ##ndi ##zed and un ##in ##formed that they want to continue in this police state we now live in where we have half of the worlds jail population but america is [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no one has ever died from a marijuana overdose you need at least 300 times the into ##xi ##cating amount to die so why are there any guidelines for marijuana other than it should be treated like alcohol with alcohol no one registers no one is tracked no one is limited so why the ongoing freak out on marijuana we need to stop acting like its some kind of heavy criminal drug thing o we should really ask ourselves what the heck are people we have let be in charge trying to stop by not legal ##izing marijuana or limiting marijuana and putting out propaganda and sensation ##ali ##zed false police reports o are they part of the dea are they part of the police are they part of the judicial system because all of those people i just mentioned are very biased because they are protecting their jobs that oversees the millions of lives they destroy on pot crimes that would go away if pot was legal ##ized o o or are these fighters of legal ##ization so prop ##aga ##ndi ##zed and un ##in ##formed that they want to continue in this police state we now live in where we have half of the worlds jail population but america is [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 2028 2038 2412 2351 2013 1037 16204 26641 2017 2342 2012 2560 3998 2335 1996 2046 9048 18252 3815 2000 3280 2061 2339 2024 2045 2151 11594 2005 16204 2060 2084 2009 2323 2022 5845 2066 6544 2007 6544 2053 2028 18687 2053 2028 2003 12808 2053 2028 2003 3132 2061 2339 1996 7552 11576 2041 2006 16204 2057 2342 2000 2644 3772 2066 2049 2070 2785 1997 3082 4735 4319 2518 1051 2057 2323 2428 3198 9731 2054 1996 17752 2024 2111 2057 2031 2292 2022 1999 3715 2667 2000 2644 2011 2025 3423 6026 16204 2030 14879 16204 1998 5128 2041 10398 1998 8742 11475 5422 6270 2610 4311 1051 2024 2027 2112 1997 1996 26709 2024 2027 2112 1997 1996 2610 2024 2027 2112 1997 1996 8268 2291 2138 2035 1997 2216 2111 1045 2074 3855 2024 2200 25352 2138 2027 2024 8650 2037 5841 2008 22558 1996 8817 1997 3268 2027 6033 2006 8962 6997 2008 2052 2175 2185 2065 8962 2001 3423 3550 1051 1051 2030 2024 2122 7299 1997 3423 3989 2061 17678 16098 16089 5422 1998 4895 2378 29021 2008 2027 2215 2000 3613 1999 2023 2610 2110 2057 2085 2444 1999 2073 2057 2031 2431 1997 1996 8484 7173 2313 2021 2637 2003 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 2028 2038 2412 2351 2013 1037 16204 26641 2017 2342 2012 2560 3998 2335 1996 2046 9048 18252 3815 2000 3280 2061 2339 2024 2045 2151 11594 2005 16204 2060 2084 2009 2323 2022 5845 2066 6544 2007 6544 2053 2028 18687 2053 2028 2003 12808 2053 2028 2003 3132 2061 2339 1996 7552 11576 2041 2006 16204 2057 2342 2000 2644 3772 2066 2049 2070 2785 1997 3082 4735 4319 2518 1051 2057 2323 2428 3198 9731 2054 1996 17752 2024 2111 2057 2031 2292 2022 1999 3715 2667 2000 2644 2011 2025 3423 6026 16204 2030 14879 16204 1998 5128 2041 10398 1998 8742 11475 5422 6270 2610 4311 1051 2024 2027 2112 1997 1996 26709 2024 2027 2112 1997 1996 2610 2024 2027 2112 1997 1996 8268 2291 2138 2035 1997 2216 2111 1045 2074 3855 2024 2200 25352 2138 2027 2024 8650 2037 5841 2008 22558 1996 8817 1997 3268 2027 6033 2006 8962 6997 2008 2052 2175 2185 2065 8962 2001 3423 3550 1051 1051 2030 2024 2122 7299 1997 3423 3989 2061 17678 16098 16089 5422 1998 4895 2378 29021 2008 2027 2215 2000 3613 1999 2023 2610 2110 2057 2085 2444 1999 2073 2057 2031 2431 1997 1996 8484 7173 2313 2021 2637 2003 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] they destroy on pot crimes that would go away if pot was legal ##ized o o or are these fighters of legal ##ization so prop ##aga ##ndi ##zed and un ##in ##formed that they want to continue in this police state we now live in where we have half of the worlds jail population but america is only four percent of the worlds population o please think about what ##s driving that o the eu has 700 000 000 million people but only 10 of the jail population america has are the american people worse people then the rest of the world that ##s a true statement 320 000 000 million americans 7 500 000 000 billion people world wide we are 4 of the world but we have 50 of the worlds prisoners counting probation and parole you can find the numbers yourself on usage attorney general and i do think probation and parole counts they are still the state controlling the population 2012 800 000 people arrested in the us for simple possession of pot nation wide the fbi says they did and average of 6 months each in prison o these 800 000 people are our friends and family members you know them so no one [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] they destroy on pot crimes that would go away if pot was legal ##ized o o or are these fighters of legal ##ization so prop ##aga ##ndi ##zed and un ##in ##formed that they want to continue in this police state we now live in where we have half of the worlds jail population but america is only four percent of the worlds population o please think about what ##s driving that o the eu has 700 000 000 million people but only 10 of the jail population america has are the american people worse people then the rest of the world that ##s a true statement 320 000 000 million americans 7 500 000 000 billion people world wide we are 4 of the world but we have 50 of the worlds prisoners counting probation and parole you can find the numbers yourself on usage attorney general and i do think probation and parole counts they are still the state controlling the population 2012 800 000 people arrested in the us for simple possession of pot nation wide the fbi says they did and average of 6 months each in prison o these 800 000 people are our friends and family members you know them so no one [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2027 6033 2006 8962 6997 2008 2052 2175 2185 2065 8962 2001 3423 3550 1051 1051 2030 2024 2122 7299 1997 3423 3989 2061 17678 16098 16089 5422 1998 4895 2378 29021 2008 2027 2215 2000 3613 1999 2023 2610 2110 2057 2085 2444 1999 2073 2057 2031 2431 1997 1996 8484 7173 2313 2021 2637 2003 2069 2176 3867 1997 1996 8484 2313 1051 3531 2228 2055 2054 2015 4439 2008 1051 1996 7327 2038 6352 2199 2199 2454 2111 2021 2069 2184 1997 1996 7173 2313 2637 2038 2024 1996 2137 2111 4788 2111 2059 1996 2717 1997 1996 2088 2008 2015 1037 2995 4861 13710 2199 2199 2454 4841 1021 3156 2199 2199 4551 2111 2088 2898 2057 2024 1018 1997 1996 2088 2021 2057 2031 2753 1997 1996 8484 5895 10320 19703 1998 17393 2017 2064 2424 1996 3616 4426 2006 8192 4905 2236 1998 1045 2079 2228 19703 1998 17393 9294 2027 2024 2145 1996 2110 9756 1996 2313 2262 5385 2199 2111 4727 1999 1996 2149 2005 3722 6664 1997 8962 3842 2898 1996 8495 2758 2027 2106 1998 2779 1997 1020 2706 2169 1999 3827 1051 2122 5385 2199 2111 2024 2256 2814 1998 2155 2372 2017 2113 2068 2061 2053 2028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2027 6033 2006 8962 6997 2008 2052 2175 2185 2065 8962 2001 3423 3550 1051 1051 2030 2024 2122 7299 1997 3423 3989 2061 17678 16098 16089 5422 1998 4895 2378 29021 2008 2027 2215 2000 3613 1999 2023 2610 2110 2057 2085 2444 1999 2073 2057 2031 2431 1997 1996 8484 7173 2313 2021 2637 2003 2069 2176 3867 1997 1996 8484 2313 1051 3531 2228 2055 2054 2015 4439 2008 1051 1996 7327 2038 6352 2199 2199 2454 2111 2021 2069 2184 1997 1996 7173 2313 2637 2038 2024 1996 2137 2111 4788 2111 2059 1996 2717 1997 1996 2088 2008 2015 1037 2995 4861 13710 2199 2199 2454 4841 1021 3156 2199 2199 4551 2111 2088 2898 2057 2024 1018 1997 1996 2088 2021 2057 2031 2753 1997 1996 8484 5895 10320 19703 1998 17393 2017 2064 2424 1996 3616 4426 2006 8192 4905 2236 1998 1045 2079 2228 19703 1998 17393 9294 2027 2024 2145 1996 2110 9756 1996 2313 2262 5385 2199 2111 4727 1999 1996 2149 2005 3722 6664 1997 8962 3842 2898 1996 8495 2758 2027 2106 1998 2779 1997 1020 2706 2169 1999 3827 1051 2122 5385 2199 2111 2024 2256 2814 1998 2155 2372 2017 2113 2068 2061 2053 2028 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 18716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 18716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] why are blacks hated part 1 african americans account for 28 of all arrests 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 51 of murders 3 92 times compared to what it should be according to their population whites have a 0 66 ratio african americans account for 30 of rape ##s 2 30 times compared to what it should be according to their population whites have a 0 97 ratio african americans account for 56 of robbery ##s 4 30 times compared to what it should be according to their population whites have a 0 61 ratio african americans account for 33 of aggravated assaults 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 30 of bu ##rg ##lary ##s 2 31 times compared to what it should be according to their population whites have a 0 97 ratio african americans account for 28 of la ##rce ##ny theft ##s 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 31 of vehicle theft ##s 2 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] why are blacks hated part 1 african americans account for 28 of all arrests 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 51 of murders 3 92 times compared to what it should be according to their population whites have a 0 66 ratio african americans account for 30 of rape ##s 2 30 times compared to what it should be according to their population whites have a 0 97 ratio african americans account for 56 of robbery ##s 4 30 times compared to what it should be according to their population whites have a 0 61 ratio african americans account for 33 of aggravated assaults 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 30 of bu ##rg ##lary ##s 2 31 times compared to what it should be according to their population whites have a 0 97 ratio african americans account for 28 of la ##rce ##ny theft ##s 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 31 of vehicle theft ##s 2 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2339 2024 10823 6283 2112 1015 3060 4841 4070 2005 2654 1997 2035 17615 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 4868 1997 9916 1017 6227 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5764 6463 3060 4841 4070 2005 2382 1997 9040 2015 1016 2382 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 5179 1997 13742 2015 1018 2382 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6079 6463 3060 4841 4070 2005 3943 1997 25817 22664 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2382 1997 20934 10623 28221 2015 1016 2861 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 2654 1997 2474 19170 4890 11933 2015 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 2861 1997 4316 11933 2015 1016 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2339 2024 10823 6283 2112 1015 3060 4841 4070 2005 2654 1997 2035 17615 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 4868 1997 9916 1017 6227 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5764 6463 3060 4841 4070 2005 2382 1997 9040 2015 1016 2382 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 5179 1997 13742 2015 1018 2382 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6079 6463 3060 4841 4070 2005 3943 1997 25817 22664 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2382 1997 20934 10623 28221 2015 1016 2861 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 2654 1997 2474 19170 4890 11933 2015 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 2861 1997 4316 11933 2015 1016 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what it should be according to their population whites have a 0 97 ratio african americans account for 28 of la ##rce ##ny theft ##s 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 31 of vehicle theft ##s 2 38 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 23 of arson crimes 1 77 times compared to what it should be according to their population whites have a 1 06 ratio african americans account for 38 of violent crimes 2 92 times compared to what it should be according to their population whites have a 0 86 ratio african americans account for 28 of property crime 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 32 of other assault crimes 2 46 times compared to what it should be according to their population whites have a 0 94 ratio african americans account for 34 of forge ##ry and counter ##feit ##ing crimes 2 62 times compared to what it should be according to their population [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] what it should be according to their population whites have a 0 97 ratio african americans account for 28 of la ##rce ##ny theft ##s 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 31 of vehicle theft ##s 2 38 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 23 of arson crimes 1 77 times compared to what it should be according to their population whites have a 1 06 ratio african americans account for 38 of violent crimes 2 92 times compared to what it should be according to their population whites have a 0 86 ratio african americans account for 28 of property crime 2 15 times compared to what it should be according to their population whites have a 1 00 ratio african americans account for 32 of other assault crimes 2 46 times compared to what it should be according to their population whites have a 0 94 ratio african americans account for 34 of forge ##ry and counter ##feit ##ing crimes 2 62 times compared to what it should be according to their population [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 2654 1997 2474 19170 4890 11933 2015 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 2861 1997 4316 11933 2015 1016 4229 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 2603 1997 24912 6997 1015 6255 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5757 6463 3060 4841 4070 2005 4229 1997 6355 6997 1016 6227 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6564 6463 3060 4841 4070 2005 2654 1997 3200 4126 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 3590 1997 2060 6101 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6365 6463 3060 4841 4070 2005 4090 1997 15681 2854 1998 4675 21156 2075 6997 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5989 6463 3060 4841 4070 2005 2654 1997 2474 19170 4890 11933 2015 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 2861 1997 4316 11933 2015 1016 4229 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 2603 1997 24912 6997 1015 6255 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5757 6463 3060 4841 4070 2005 4229 1997 6355 6997 1016 6227 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6564 6463 3060 4841 4070 2005 2654 1997 3200 4126 1016 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 4002 6463 3060 4841 4070 2005 3590 1997 2060 6101 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6365 6463 3060 4841 4070 2005 4090 1997 15681 2854 1998 4675 21156 2075 6997 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] americans account for 32 of other assault crimes 2 46 times compared to what it should be according to their population whites have a 0 94 ratio african americans account for 34 of forge ##ry and counter ##feit ##ing crimes 2 62 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 32 of fraud 2 46 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 36 of em ##be ##zzle ##ment crimes 2 77 times compared to what it should be according to their population whites have a 0 90 ratio african americans account for 32 of buying receiving possessing stolen property crimes 2 46 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 27 of van ##dal ##ism crimes 2 07 times compared to what it should be according to their population whites have a 1 01 ratio african americans account for 41 of weapons crimes 3 15 times compared to what it should be according to their population whites have a 0 83 ratio african americans account for 42 of [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] americans account for 32 of other assault crimes 2 46 times compared to what it should be according to their population whites have a 0 94 ratio african americans account for 34 of forge ##ry and counter ##feit ##ing crimes 2 62 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 32 of fraud 2 46 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 36 of em ##be ##zzle ##ment crimes 2 77 times compared to what it should be according to their population whites have a 0 90 ratio african americans account for 32 of buying receiving possessing stolen property crimes 2 46 times compared to what it should be according to their population whites have a 0 96 ratio african americans account for 27 of van ##dal ##ism crimes 2 07 times compared to what it should be according to their population whites have a 1 01 ratio african americans account for 41 of weapons crimes 3 15 times compared to what it should be according to their population whites have a 0 83 ratio african americans account for 42 of [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4841 4070 2005 3590 1997 2060 6101 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6365 6463 3060 4841 4070 2005 4090 1997 15681 2854 1998 4675 21156 2075 6997 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 3590 1997 9861 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 4029 1997 7861 4783 17644 3672 6997 1016 6255 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 3938 6463 3060 4841 4070 2005 3590 1997 9343 4909 18840 7376 3200 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 2676 1997 3158 9305 2964 6997 1016 5718 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5890 6463 3060 4841 4070 2005 4601 1997 4255 6997 1017 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6640 6463 3060 4841 4070 2005 4413 1997 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4841 4070 2005 3590 1997 2060 6101 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6365 6463 3060 4841 4070 2005 4090 1997 15681 2854 1998 4675 21156 2075 6997 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 3590 1997 9861 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 4029 1997 7861 4783 17644 3672 6997 1016 6255 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 3938 6463 3060 4841 4070 2005 3590 1997 9343 4909 18840 7376 3200 6997 1016 4805 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5986 6463 3060 4841 4070 2005 2676 1997 3158 9305 2964 6997 1016 5718 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5890 6463 3060 4841 4070 2005 4601 1997 4255 6997 1017 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6640 6463 3060 4841 4070 2005 4413 1997 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] times compared to what it should be according to their population whites have a 1 01 ratio african americans account for 41 of weapons crimes 3 15 times compared to what it should be according to their population whites have a 0 83 ratio african americans account for 42 of prostitution crimes 3 23 times compared to what it should be according to their population whites have a 0 78 ratio african americans account for 24 of other sex related crimes 1 85 times compared to what it should be according to their population whites have a 1 04 ratio african americans account for 29 of drug abuse crimes 2 23 times compared to what it should be according to their population whites have a 0 86 ratio african americans account for 59 of gambling crimes 4 54 times compared to what it should be according to their population whites have a 0 52 ratio african americans account for 33 of domestic violence crimes 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 13 of du ##i violations 1 0 times compared to what it should be [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] times compared to what it should be according to their population whites have a 1 01 ratio african americans account for 41 of weapons crimes 3 15 times compared to what it should be according to their population whites have a 0 83 ratio african americans account for 42 of prostitution crimes 3 23 times compared to what it should be according to their population whites have a 0 78 ratio african americans account for 24 of other sex related crimes 1 85 times compared to what it should be according to their population whites have a 1 04 ratio african americans account for 29 of drug abuse crimes 2 23 times compared to what it should be according to their population whites have a 0 86 ratio african americans account for 59 of gambling crimes 4 54 times compared to what it should be according to their population whites have a 0 52 ratio african americans account for 33 of domestic violence crimes 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 13 of du ##i violations 1 0 times compared to what it should be [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5890 6463 3060 4841 4070 2005 4601 1997 4255 6997 1017 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6640 6463 3060 4841 4070 2005 4413 1997 15016 6997 1017 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6275 6463 3060 4841 4070 2005 2484 1997 2060 3348 3141 6997 1015 5594 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5840 6463 3060 4841 4070 2005 2756 1997 4319 6905 6997 1016 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6564 6463 3060 4841 4070 2005 5354 1997 12219 6997 1018 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 4720 6463 3060 4841 4070 2005 3943 1997 4968 4808 6997 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2410 1997 4241 2072 13302 1015 1014 2335 4102 2000 2054 2009 2323 2022 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5890 6463 3060 4841 4070 2005 4601 1997 4255 6997 1017 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6640 6463 3060 4841 4070 2005 4413 1997 15016 6997 1017 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6275 6463 3060 4841 4070 2005 2484 1997 2060 3348 3141 6997 1015 5594 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 5840 6463 3060 4841 4070 2005 2756 1997 4319 6905 6997 1016 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6564 6463 3060 4841 4070 2005 5354 1997 12219 6997 1018 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 4720 6463 3060 4841 4070 2005 3943 1997 4968 4808 6997 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2410 1997 4241 2072 13302 1015 1014 2335 4102 2000 2054 2009 2323 2022 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] have a 0 52 ratio african americans account for 33 of domestic violence crimes 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 13 of du ##i violations 1 0 times compared to what it should be according to their population whites have a 1 22 ratio african americans account for 15 of liquor laws violations 1 15 times compared to what it should be according to their population whites have a 1 16 ratio african americans account for 16 of drunken ##ness crimes 1 23 times compared to what it should be according to their population whites have a 1 17 ratio african americans account for 34 of disorder ##ly conduct 2 62 times compared to what it should be according to their population whites have a 0 91 ratio african americans account for 30 of all other offenses except traffic 2 31 times compared to what it should be according to their population whites have a 0 98 ratio african americans account for 46 of cu ##rf ##ew and lo ##iter ##ing violations 3 54 times compared to what it should be according to their population whites have a 0 74 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] have a 0 52 ratio african americans account for 33 of domestic violence crimes 2 54 times compared to what it should be according to their population whites have a 0 93 ratio african americans account for 13 of du ##i violations 1 0 times compared to what it should be according to their population whites have a 1 22 ratio african americans account for 15 of liquor laws violations 1 15 times compared to what it should be according to their population whites have a 1 16 ratio african americans account for 16 of drunken ##ness crimes 1 23 times compared to what it should be according to their population whites have a 1 17 ratio african americans account for 34 of disorder ##ly conduct 2 62 times compared to what it should be according to their population whites have a 0 91 ratio african americans account for 30 of all other offenses except traffic 2 31 times compared to what it should be according to their population whites have a 0 98 ratio african americans account for 46 of cu ##rf ##ew and lo ##iter ##ing violations 3 54 times compared to what it should be according to their population whites have a 0 74 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2031 1037 1014 4720 6463 3060 4841 4070 2005 3943 1997 4968 4808 6997 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2410 1997 4241 2072 13302 1015 1014 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2570 6463 3060 4841 4070 2005 2321 1997 13207 4277 13302 1015 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2385 6463 3060 4841 4070 2005 2385 1997 15967 2791 6997 1015 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2459 6463 3060 4841 4070 2005 4090 1997 8761 2135 6204 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6205 6463 3060 4841 4070 2005 2382 1997 2035 2060 25173 3272 4026 1016 2861 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5818 6463 3060 4841 4070 2005 4805 1997 12731 12881 7974 1998 8840 21646 2075 13302 1017 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6356 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2031 1037 1014 4720 6463 3060 4841 4070 2005 3943 1997 4968 4808 6997 1016 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6109 6463 3060 4841 4070 2005 2410 1997 4241 2072 13302 1015 1014 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2570 6463 3060 4841 4070 2005 2321 1997 13207 4277 13302 1015 2321 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2385 6463 3060 4841 4070 2005 2385 1997 15967 2791 6997 1015 2603 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1015 2459 6463 3060 4841 4070 2005 4090 1997 8761 2135 6204 1016 5786 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6205 6463 3060 4841 4070 2005 2382 1997 2035 2060 25173 3272 4026 1016 2861 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 5818 6463 3060 4841 4070 2005 4805 1997 12731 12881 7974 1998 8840 21646 2075 13302 1017 5139 2335 4102 2000 2054 2009 2323 2022 2429 2000 2037 2313 12461 2031 1037 1014 6356 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "OLkn7RQ8_CV1",
    "outputId": "1a64e756-c761-42e2-b205-058b9b1369c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :  I used to think the RocknRoll Hall of Fame meant royalty until I discovered WHO started it and why Im surprised someone didnt beat Jann Werner to it Gotta give him credit for pushing forth HIS pet project but in truth its a personal club HIS club The people have very little to do with the selection I agree with quite a few on your list No 1 being Love Arthur Lee was a visionary Fire up the song Seven and Seven and see if you can sit still Anytime I want a caffeine jolt this is the song that does it I can live with Journey Steve Perrys voice is a classic I agree about the Cure But add another C band the Cult Ian Astburys is as powerful as any singer whoever stood behind a mic Metal bands Type O Negative and Rammstein Two of the finest ever Definitely two of my favs ToNs lead singer Peter Steele had a persona about him that still resonates five years after his death Rammstein is simply riveting to watch Theres no opera ever written that can create the powerful emotions than these guys produce with their brand of music and\n",
      "------------------------------\n",
      "Tokens :  ['i', 'used', 'to', 'think', 'the', 'rock', '##nr', '##oll', 'hall', 'of', 'fame', 'meant', 'royalty', 'until', 'i', 'discovered', 'who', 'started', 'it', 'and', 'why', 'im', 'surprised', 'someone', 'didn', '##t', 'beat', 'jan', '##n', 'werner', 'to', 'it', 'gotta', 'give', 'him', 'credit', 'for', 'pushing', 'forth', 'his', 'pet', 'project', 'but', 'in', 'truth', 'its', 'a', 'personal', 'club', 'his', 'club', 'the', 'people', 'have', 'very', 'little', 'to', 'do', 'with', 'the', 'selection', 'i', 'agree', 'with', 'quite', 'a', 'few', 'on', 'your', 'list', 'no', '1', 'being', 'love', 'arthur', 'lee', 'was', 'a', 'visionary', 'fire', 'up', 'the', 'song', 'seven', 'and', 'seven', 'and', 'see', 'if', 'you', 'can', 'sit', 'still', 'anytime', 'i', 'want', 'a', 'caf', '##fe', '##ine', 'jolt', 'this', 'is', 'the', 'song', 'that', 'does', 'it', 'i', 'can', 'live', 'with', 'journey', 'steve', 'perry', '##s', 'voice', 'is', 'a', 'classic', 'i', 'agree', 'about', 'the', 'cure', 'but', 'add', 'another', 'c', 'band', 'the', 'cult', 'ian', 'as', '##t', '##bury', '##s', 'is', 'as', 'powerful', 'as', 'any', 'singer', 'whoever', 'stood', 'behind', 'a', 'mic', 'metal', 'bands', 'type', 'o', 'negative', 'and', 'ram', '##ms', '##tein', 'two', 'of', 'the', 'finest', 'ever', 'definitely', 'two', 'of', 'my', 'fa', '##vs', 'tons', 'lead', 'singer', 'peter', 'steele', 'had', 'a', 'persona', 'about', 'him', 'that', 'still', 'res', '##onate', '##s', 'five', 'years', 'after', 'his', 'death', 'ram', '##ms', '##tein', 'is', 'simply', 'ri', '##vet', '##ing', 'to', 'watch', 'there', '##s', 'no', 'opera', 'ever', 'written', 'that', 'can', 'create', 'the', 'powerful', 'emotions', 'than', 'these', 'guys', 'produce', 'with', 'their', 'brand', 'of', 'music', 'and']\n",
      "------------------------------\n",
      "Input IDs :  [101, 1045, 2109, 2000, 2228, 1996, 2600, 16118, 14511, 2534, 1997, 4476, 3214, 16664, 2127, 1045, 3603, 2040, 2318, 2009, 1998, 2339, 10047, 4527, 2619, 2134, 2102, 3786, 5553, 2078, 14121, 2000, 2009, 10657, 2507, 2032, 4923, 2005, 6183, 5743, 2010, 9004, 2622, 2021, 1999, 3606, 2049, 1037, 3167, 2252, 2010, 2252, 1996, 2111, 2031, 2200, 2210, 2000, 2079, 2007, 1996, 4989, 1045, 5993, 2007, 3243, 1037, 2261, 2006, 2115, 2862, 2053, 1015, 2108, 2293, 4300, 3389, 2001, 1037, 28036, 2543, 2039, 1996, 2299, 2698, 1998, 2698, 1998, 2156, 2065, 2017, 2064, 4133, 2145, 15933, 1045, 2215, 1037, 24689, 7959, 3170, 22538, 2023, 2003, 1996, 2299, 2008, 2515, 2009, 1045, 2064, 2444, 2007, 4990, 3889, 6890, 2015, 2376, 2003, 1037, 4438, 1045, 5993, 2055, 1996, 9526, 2021, 5587, 2178, 1039, 2316, 1996, 8754, 4775, 2004, 2102, 4917, 2015, 2003, 2004, 3928, 2004, 2151, 3220, 9444, 2768, 2369, 1037, 23025, 3384, 4996, 2828, 1051, 4997, 1998, 8223, 5244, 9589, 2048, 1997, 1996, 10418, 2412, 5791, 2048, 1997, 2026, 6904, 15088, 6197, 2599, 3220, 2848, 12872, 2018, 1037, 16115, 2055, 2032, 2008, 2145, 24501, 21149, 2015, 2274, 2086, 2044, 2010, 2331, 8223, 5244, 9589, 2003, 3432, 15544, 19510, 2075, 2000, 3422, 2045, 2015, 2053, 3850, 2412, 2517, 2008, 2064, 3443, 1996, 3928, 6699, 2084, 2122, 4364, 3965, 2007, 2037, 4435, 1997, 2189, 1998, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", train_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", train_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", train_features[0].segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piypsrPudMFf"
   },
   "source": [
    "# BERT: Creating A Multi-Class Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TBxxy9s7GCW4"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for sentiment data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rPRB5i1HG8JO"
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fNrvabUFHC79"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 4e-5\n",
    "NUM_TRAIN_EPOCHS = 2.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xo70COnsHIWE",
    "outputId": "91b8c8f6-5e43-4b9a-a2a6-43178eac02a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2339, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "zHlZKcq7HMzE",
    "outputId": "47627024-d5d1-454c-88fd-fa952a508e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5abf36aa58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5abf36aa58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "05KBWhqeHUIF"
   },
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm0AubBnhEst"
   },
   "source": [
    "# BERT: Fine Tuning Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JUhCik-iHj9o",
    "outputId": "8ce81805-8c77-45c4-bfa9-a9a2a6b85011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.313774, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.313774, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.861615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.861615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1363286, step = 100 (116.062 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1363286, step = 100 (116.062 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6563103, step = 200 (98.227 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6563103, step = 200 (98.227 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.957162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.957162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0122058, step = 300 (104.476 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0122058, step = 300 (104.476 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.91878045, step = 400 (98.225 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.91878045, step = 400 (98.225 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.9411259, step = 500 (98.226 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.9411259, step = 500 (98.226 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.964554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.964554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.96828926, step = 600 (103.675 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.96828926, step = 600 (103.675 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.95626414, step = 700 (98.222 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.95626414, step = 700 (98.222 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.83755624, step = 800 (98.215 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.83755624, step = 800 (98.215 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.964823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.964823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.94114304, step = 900 (103.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.94114304, step = 900 (103.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8227068, step = 1000 (98.221 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8227068, step = 1000 (98.221 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.82612944, step = 1100 (98.209 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.82612944, step = 1100 (98.209 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.965196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.965196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.63576645, step = 1200 (103.606 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.63576645, step = 1200 (103.606 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.76329386, step = 1300 (98.210 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.76329386, step = 1300 (98.210 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42650527, step = 1400 (98.205 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42650527, step = 1400 (98.205 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.961965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.961965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24461547, step = 1500 (103.954 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24461547, step = 1500 (103.954 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6593268, step = 1600 (98.226 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6593268, step = 1600 (98.226 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.833215, step = 1700 (98.218 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.833215, step = 1700 (98.218 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.96351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.96351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5278646, step = 1800 (103.787 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5278646, step = 1800 (103.787 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8922582, step = 1900 (98.211 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8922582, step = 1900 (98.211 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81634575, step = 2000 (98.213 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81634575, step = 2000 (98.213 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2100 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2100 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.963802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.963802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.062221, step = 2100 (103.756 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.062221, step = 2100 (103.756 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7883899, step = 2200 (98.219 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7883899, step = 2200 (98.219 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.01835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6617532, step = 2300 (98.199 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6617532, step = 2300 (98.199 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2339 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2339 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6625899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6625899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:40:55.208783\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-EFK3DS0qkm"
   },
   "source": [
    "The accuracy for the fine tuned BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "HSQxiqDPHrJy",
    "outputId": "c534a0c3-0926-4245-a0f2-ceb0c841d93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-27T23:44:48Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-27T23:44:48Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-27-23:46:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-27-23:46:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2339: eval_accuracy = 0.65392053, false_negatives = 221.0, false_positives = 581.0, global_step = 2339, loss = 0.8331493, true_negatives = 103.0, true_positives = 3750.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2339: eval_accuracy = 0.65392053, false_negatives = 221.0, false_positives = 581.0, global_step = 2339, loss = 0.8331493, true_negatives = 103.0, true_positives = 3750.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2339: /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2339: /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.65392053,\n",
       " 'false_negatives': 221.0,\n",
       " 'false_positives': 581.0,\n",
       " 'global_step': 2339,\n",
       " 'loss': 0.8331493,\n",
       " 'true_negatives': 103.0,\n",
       " 'true_positives': 3750.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrINhRKwAeil"
   },
   "source": [
    "# Validation on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0lMCMBUEAa6o"
   },
   "outputs": [],
   "source": [
    "articles_label = pd.read_excel('articles_annotated.xlsx', error_bad_lines=False, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PcO4iLhyiigk"
   },
   "outputs": [],
   "source": [
    "articles_label.loc[articles_label['Emotion']=='SAD','label'] = 'negative'\n",
    "articles_label.loc[articles_label['Emotion']=='MAD','label'] = 'negative'\n",
    "articles_label.loc[articles_label['Emotion']=='HAPPY','label'] = 'positive'\n",
    "articles_label.loc[articles_label['Emotion']=='CONFLICTED','label'] = 'mixed'\n",
    "articles_label.loc[articles_label['Emotion']=='NEUTRAL','label'] = 'positive'\n",
    "articles_label.loc[articles_label['Emotion'].isin(['Neutral','Happy','Sad']), 'label'] = 'mixed'\n",
    "train_raw = articles_label[articles_label.Humor.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j7HRykNLB6jz",
    "outputId": "40537f11-bdc6-4ad1-9f5a-5c2feedcf4e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 6)"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = articles_label[articles_label.Humor.notnull()]\n",
    "train_raw = train_raw[['text','Humor',\t'Sarcasm',\t'Positive',\t'Controversial',\t'Argumentative']]\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V_CBbJCtCwU6"
   },
   "outputs": [],
   "source": [
    "train_raw['label'] = np.argmax(np.array(train_raw[['Humor',\t'Sarcasm',\t'Positive',\t'Controversial',\t'Argumentative']])==1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "ZEny5Jq4B6j4",
    "outputId": "ba6afdcc-177a-49a0-b0f4-f5c06a9b95da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5a535dc518>"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQE0lEQVR4nO3df6xkZX3H8feHBQXUiMi63fDDuyiRkohIr6hRW4VYf1AFW0qx2m4a4jZVE41t6mqNYtIm2ERRGyuuQrpaFRBFqGhbWFeNf3RxEUR+SFlxaUFg1x8IWCMufvvHnCuX5e69c+/eM8O9z/uVTOY5z5yZ831y9n72zDNnzqSqkCS1Y59xFyBJGi2DX5IaY/BLUmMMfklqjMEvSY3Zd9wFDOOQQw6piYmJcZchSUvK1Vdf/aOqWrl7/5II/omJCbZu3TruMiRpSUly20z9TvVIUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjlsQ3dyUJYGL95WPZ7vazTx7LdvviEb8kNcbgl6TGGPyS1Bjn+CXNy7jm2bV4eg3+JNuB+4AHgV1VNZnkYOBCYALYDpxeVT/tsw5J0kNGMdXzkqo6rqomu+X1wKaqOgrY1C1LkkZkHHP8pwAbu/ZG4NQx1CBJzeo7+Av4zyRXJ1nX9a2qqju79l3AqpmemGRdkq1Jtu7cubPnMiWpHX1/uPvCqrojyVOAK5J8b/qDVVVJaqYnVtUGYAPA5OTkjOtIkuav1yP+qrqju98BXAKcANydZDVAd7+jzxokSQ/XW/AneVySJ0y1gd8HrgcuA9Z2q60FLu2rBknSI/U51bMKuCTJ1HY+U1X/nuRbwEVJzgRuA07vsQZJ0m56C/6quhV41gz9PwZO6mu7kqTZeckGSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmH3HXYC0lE2sv3xs295+9slj27aWNo/4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqTO/Bn2RFkmuSfKlbXpNkS5JtSS5M8pi+a5AkPWQUR/xvAW6atvw+4JyqejrwU+DMEdQgSer0GvxJDgNOBj7RLQc4Ebi4W2UjcGqfNUiSHq7vI/4PAn8L/LpbfjJwT1Xt6pZvBw7tuQZJ0jS9BX+SPwB2VNXVC3z+uiRbk2zduXPnIlcnSe3q84j/BcCrk2wHLmAwxfMh4KAkUxeHOwy4Y6YnV9WGqpqsqsmVK1f2WKYktaW34K+qd1TVYVU1AZwBfLWqXgdsBk7rVlsLXNpXDZKkRxrHefxvB96WZBuDOf/zxlCDJDVrJNfjr6qvAV/r2rcCJ4xiu5KkR/Kbu5LUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTFDBX+SZ/ZdiCRpNIY94v/nJFcleWOSJ/ZakSSpV0MFf1W9CHgdcDhwdZLPJHlpr5VJknox9Bx/Vd0CvAt4O/B7wIeTfC/JH/ZVnCRp8Q07x39sknOAm4ATgVdV1W937XN6rE+StMj2HXK9fwI+Abyzqn4x1VlVP0zyrl4qkyT1YtjgPxn4RVU9CJBkH2D/qvq/qvpUb9VJkhbdsHP8VwIHTFs+sOuTJC0xwwb//lV1/9RC1z6wn5IkSX0aNvh/nuT4qYUkvwP8Ypb1SbJ/d+7/d5LckOS9Xf+aJFuSbEtyYZLHLLx8SdJ8DTvH/1bgc0l+CAT4LeBP5njOL4ETq+r+JPsB30zyFeBtwDlVdUGSc4EzgY8urHxJ0nwNFfxV9a0kRwPP6LpurqpfzfGcAqamh/brbsXgFNA/7fo3Amdh8EvSyAx7xA/wHGCie87xSaiqT872hCQrgKuBpwMfAb4P3FNVu7pVbgcO3cNz1wHrAI444oh5lClJi2ti/eVj2e72s0/u5XWHCv4knwKeBlwLPNh1FzBr8Henfx6X5CDgEuDoYQurqg3ABoDJycka9nmSpNkNe8Q/CRzTTd/MW1Xdk2Qz8HzgoCT7dkf9hwF3LOQ1JUkLM+xZPdcz+EB3aElWdkf6JDkAeCmDSz5sBk7rVlsLXDqf15Uk7Z1hj/gPAW5MchWDs3UAqKpXz/Kc1cDGbp5/H+CiqvpSkhuBC5L8PXANcN7CSpckLcSwwX/WfF+4qq4Dnj1D/63ACfN9PUnS4hj2dM6vJ3kqcFRVXZnkQGBFv6VJkvow7GWZ3wBcDHys6zoU+GJfRUmS+jPsVM+bGEzPbIHBj7IkeUpvVUma07jOLdfSN+xZPb+sqgemFpLsy+A8fknSEjNs8H89yTuBA7rf2v0c8G/9lSVJ6suwwb8e2Al8F/hL4MsMfn9XkrTEDHtWz6+Bj3c36VHH+W5peMNeq+cHzDCnX1VHLnpFkqRezedaPVP2B/4YOHjxy5Ek9W2oOf6q+vG02x1V9UEGP8AuSVpihp3qOX7a4j4M3gHM51r+kqRHiWHD+/3T2ruA7cDpi16NJKl3w57V85K+C5EkjcawUz1vm+3xqvrA4pQjSerbfM7qeQ5wWbf8KuAq4JY+ipIk9WfY4D8MOL6q7gNIchZweVW9vq/CJEn9GPaSDauAB6YtP9D1SZKWmGGP+D8JXJXkkm75VGBjPyVJkvo07Fk9/5DkK8CLuq6/qKpr+itLktSXYad6AA4E7q2qDwG3J1nTU02SpB4N+9OL7wHeDryj69oP+Ne+ipIk9WfYI/7XAK8Gfg5QVT8EntBXUZKk/gwb/A9UVdFdmjnJ4/orSZLUp2GD/6IkHwMOSvIG4Er8URZJWpLmPKsnSYALgaOBe4FnAO+uqit6rk2S1IM5g7+qKsmXq+qZgGEvSUvcsFM9307ynF4rkSSNxLDf3H0u8Pok2xmc2RMGbwaO7aswSVI/Zg3+JEdU1f8ALxtRPZKkns11xP9FBlflvC3J56vqj0ZRlCSpP3PN8Wda+8g+C5EkjcZcwV97aM8pyeFJNie5MckNSd7S9R+c5Iokt3T3T5pv0ZKkhZsr+J+V5N4k9wHHdu17k9yX5N45nrsL+OuqOgZ4HvCmJMcA64FNVXUUsKlbliSNyKxz/FW1YqEvXFV3And27fuS3AQcCpwCvLhbbSPwNQYXgJMkjcB8Lsu8YEkmgGcDW4BV3X8KAHexh1/ySrIuydYkW3fu3DmKMiWpCb0Hf5LHA58H3lpVD5semn7ht91V1YaqmqyqyZUrV/ZdpiQ1o9fgT7Ifg9D/dFV9oeu+O8nq7vHVwI4+a5AkPVxvwd9d3O084Kaq+sC0hy4D1nbttcClfdUgSXqkYS/ZsBAvAP4M+G6Sa7u+dwJnM7jM85nAbcDpPdYgSdpNb8FfVd/k4V8Am+6kvrYrSZrdSM7qkSQ9ehj8ktQYg1+SGmPwS1JjDH5JaozBL0mN6fM8fjVmYv3l4y5B0hA84pekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDWmt+BPcn6SHUmun9Z3cJIrktzS3T+pr+1LkmbW5xH/vwAv361vPbCpqo4CNnXLkqQR6i34q+obwE926z4F2Ni1NwKn9rV9SdLMRj3Hv6qq7uzadwGr9rRiknVJtibZunPnztFUJ0kNGNuHu1VVQM3y+IaqmqyqyZUrV46wMkla3kYd/HcnWQ3Q3e8Y8fYlqXmjDv7LgLVdey1w6Yi3L0nN27evF07yWeDFwCFJbgfeA5wNXJTkTOA24PS+tt+yifWXj7sESY9ivQV/Vb12Dw+d1Nc2JUlz85u7ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGrPvuAvo28T6y8ey3e1nnzyW7UrSXDzil6TGGPyS1BiDX5Ias+zn+MdlXJ8tSNJcxnLEn+TlSW5Osi3J+nHUIEmtGnnwJ1kBfAR4BXAM8Nokx4y6Dklq1TiO+E8AtlXVrVX1AHABcMoY6pCkJo1jjv9Q4H+nLd8OPHf3lZKsA9Z1i/cnuXkEtfXlEOBH4y5iDBx3Wxz3Isv79volnjpT56P2w92q2gBsGHcdiyHJ1qqaHHcdo+a42+K4l45xTPXcARw+bfmwrk+SNALjCP5vAUclWZPkMcAZwGVjqEOSmjTyqZ6q2pXkzcB/ACuA86vqhlHXMWLLYspqARx3Wxz3EpGqGncNkqQR8pINktQYg1+SGmPwL4Ik5yfZkeT6aX0HJ7kiyS3d/ZO6/iT5cHe5iuuSHD++yvfOHsZ9VpI7klzb3V457bF3dOO+OcnLxlP13klyeJLNSW5MckOSt3T9y3p/zzLu5b6/909yVZLvdON+b9e/JsmWbnwXdieqkOSx3fK27vGJcda/R1XlbS9vwO8CxwPXT+v7R2B9114PvK9rvxL4ChDgecCWcde/yOM+C/ibGdY9BvgO8FhgDfB9YMW4x7CAMa8Gju/aTwD+uxvbst7fs4x7ue/vAI/v2vsBW7r9eBFwRtd/LvBXXfuNwLld+wzgwnGPYaabR/yLoKq+Afxkt+5TgI1deyNw6rT+T9bAfwEHJVk9mkoX1x7GvSenABdU1S+r6gfANgaX71hSqurOqvp2174PuInBt9GX9f6eZdx7slz2d1XV/d3ift2tgBOBi7v+3ff31L+Di4GTkmRE5Q7N4O/Pqqq6s2vfBazq2jNdsmK2P6Cl6M3dtMb5U1MeLMNxd2/jn83gKLCZ/b3buGGZ7+8kK5JcC+wArmDw7uWeqtrVrTJ9bL8Zd/f4z4Anj7biuRn8I1CD932tnDf7UeBpwHHAncD7x1tOP5I8Hvg88Naqunf6Y8t5f88w7mW/v6vqwao6jsFVBk4Ajh5zSXvN4O/P3VNv6bv7HV3/sr5kRVXd3f2h/Br4OA+9vV82406yH4Pw+3RVfaHrXvb7e6Zxt7C/p1TVPcBm4PkMpuymvgA7fWy/GXf3+BOBH4+41DkZ/P25DFjbtdcCl07r//PubI/nAT+bNkWw5O02f/0aYOqMn8uAM7qzHtYARwFXjbq+vdXN154H3FRVH5j20LLe33sadwP7e2WSg7r2AcBLGXy+sRk4rVtt9/099e/gNOCr3TvAR5dxf7q8HG7AZxm8zf0Vg/m+MxnM620CbgGuBA6uh84S+AiDecLvApPjrn+Rx/2pblzXMfgjWD1t/b/rxn0z8Ipx17/AMb+QwTTOdcC13e2Vy31/zzLu5b6/jwWu6cZ3PfDurv9IBv+RbQM+Bzy269+/W97WPX7kuMcw081LNkhSY5zqkaTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMf8PzhOebhIOa/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw.text.apply(lambda x: len(x.split())).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "y-yjZx_vB6j7",
    "outputId": "5af4c43e-0e66-4d7e-a5fa-92cdf6080340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Length</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Controversial</th>\n",
       "      <th>Argumentative</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>641.750000</td>\n",
       "      <td>233.003846</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>236.642308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>388.521426</td>\n",
       "      <td>48.693074</td>\n",
       "      <td>0.419650</td>\n",
       "      <td>0.365155</td>\n",
       "      <td>0.471398</td>\n",
       "      <td>0.488340</td>\n",
       "      <td>0.476660</td>\n",
       "      <td>49.504094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321.500000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>633.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>940.250000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1348.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>319.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index      Length  ...  Argumentative     len_txt\n",
       "count   260.000000  260.000000  ...     260.000000  260.000000\n",
       "mean    641.750000  233.003846  ...       0.346154  236.642308\n",
       "std     388.521426   48.693074  ...       0.476660   49.504094\n",
       "min       2.000000   72.000000  ...       0.000000   73.000000\n",
       "25%     321.500000  198.000000  ...       0.000000  201.500000\n",
       "50%     633.500000  245.000000  ...       0.000000  246.500000\n",
       "75%     940.250000  276.000000  ...       1.000000  278.000000\n",
       "max    1348.000000  302.000000  ...       1.000000  319.000000\n",
       "\n",
       "[8 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['len_txt'] =train_raw.text.apply(lambda x: len(x.split()))\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbWwArBYB6j_",
    "outputId": "88cd97d8-9dee-430a-9e82-045c44bea9db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 13)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFDdqeAvB6kB"
   },
   "source": [
    "Select only the row with number of words greater than 250:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3sMVU_7TB6kC",
    "outputId": "4853bdb1-1dc0-4a73-daa1-cb55200b0a61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_raw = train_raw[train_raw.len_txt >249]\n",
    "#train_raw.shape\n",
    "ind = train_raw.len_txt >512\n",
    "ind.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbEojVRvB6kG"
   },
   "source": [
    "Group similar products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "IfjXvaIoB6kJ",
    "outputId": "11de11a6-c6e2-41d5-d1f8-0f2e27a9f77c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5a05f3f0f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw['label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Sc-y71_OB6kN"
   },
   "outputs": [],
   "source": [
    "train_raw = train_raw[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "uwJwdNycB6kQ",
    "outputId": "c12510a6-7b5f-42b7-bfd1-2b0e8834f151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yet again, America's drug abuse problem takes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A leader of the American Family Association, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump’s campaign chairman Paul Manafort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah McBride peed the other day. But it wasn’...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trolling can take many forms, and on a recent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Yet again, America's drug abuse problem takes ...      0\n",
       "1  A leader of the American Family Association, w...      0\n",
       "2  Donald Trump’s campaign chairman Paul Manafort...      0\n",
       "3  Sarah McBride peed the other day. But it wasn’...      0\n",
       "4  Trolling can take many forms, and on a recent ...      0"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pBsw62S5B6kT",
    "outputId": "99231878-415a-4e24-c759-26f44d5e38e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_raw['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dd4xqsqaB6kV"
   },
   "outputs": [],
   "source": [
    "val = train_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qcDEMj2B6ka"
   },
   "source": [
    "Clean the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FBqhcDbIB6ka"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "44-xSR_9B6kd",
    "outputId": "03bc78cc-bfbd-4601-ac6d-71c6c84b493e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yet again Americas drug abuse problem takes it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A leader of the American Family Association wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump s campaign chairman Paul Manafort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah McBride peed the other day But it wasn t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trolling can take many forms and on a recent a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Yet again Americas drug abuse problem takes it...      0\n",
       "1  A leader of the American Family Association wh...      0\n",
       "2  Donald Trump s campaign chairman Paul Manafort...      0\n",
       "3  Sarah McBride peed the other day But it wasn t...      0\n",
       "4  Trolling can take many forms and on a recent a...      0"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text']  = val.text.apply(clean_txt)\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TDkREFtPB6kx",
    "outputId": "a709ac58-7346-4a75-ab66-07c028cf3224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "val_lo = val[~val.index.isin(ind[ind==True].index)]\n",
    "val_hi = val[val.index.isin(ind[ind==True].index)]\n",
    "print(val_lo.shape)\n",
    "print(val_hi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pEX-sQGB6kz"
   },
   "source": [
    "# Splitting the Data into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ceJmqViHB6k0"
   },
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 47
    },
    "colab_type": "code",
    "id": "z_34yafoB6k4",
    "outputId": "3531d229-b343-48bd-8387-0f54949b8376"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, text_split]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hi['text_split'] = val_hi[DATA_COLUMN].apply(get_split)\n",
    "val_hi.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KFbJjGjgB6k9",
    "outputId": "38615f6e-b169-49df-b4c6-3b6eb5d976d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val_hi.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeN5axTEB6k_"
   },
   "source": [
    "The final dataset for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 47
    },
    "colab_type": "code",
    "id": "qcRIwFglB6lC",
    "outputId": "82fbadc6-2edb-4214-abf9-663aeaa39add"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6N1T_nSsGJAo"
   },
   "outputs": [],
   "source": [
    "val_df = pd.concat([val_df, val_lo], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "cqX6Wvp2fSxg",
    "outputId": "5cb44f71-29ea-4a5b-c09c-27dfb893264c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-f989e623db3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/articles_df5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/articles_df5.csv'"
     ]
    }
   ],
   "source": [
    "val_df.to_csv('/content/drive/My Drive/OMSCS/CSE6240 Web Search & Text Mining/Project/articles_df5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkNUH47dB6lI"
   },
   "source": [
    "# BERT: Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kC53p_5B6lI"
   },
   "source": [
    "Process the data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yo76Kvo4B6lI"
   },
   "outputs": [],
   "source": [
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "QjPtqueHB6lL",
    "outputId": "a41d1810-3ce6-4e99-82c9-fdd032231d4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      <bert.run_classifier.InputExample object at 0x...\n",
       "1      <bert.run_classifier.InputExample object at 0x...\n",
       "2      <bert.run_classifier.InputExample object at 0x...\n",
       "3      <bert.run_classifier.InputExample object at 0x...\n",
       "4      <bert.run_classifier.InputExample object at 0x...\n",
       "                             ...                        \n",
       "255    <bert.run_classifier.InputExample object at 0x...\n",
       "256    <bert.run_classifier.InputExample object at 0x...\n",
       "257    <bert.run_classifier.InputExample object at 0x...\n",
       "258    <bert.run_classifier.InputExample object at 0x...\n",
       "259    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 260, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "j1GpPm0oB6lN",
    "outputId": "4f2e3efd-9639-46b2-dfa3-218365abead4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  Yet again Americas drug abuse problem takes its toll White Americans life expectancy declined slightly in 2014 according to federal data reported in the New York Times dropping from 78 9 years in 2013 to 78 8 years in 2014 Â The reason Â Rising numbers of white Americans areÂ dying of drug overdoses particularly among thoseÂ in their mid 20s to mid 50s Liver disease and suicide have also reportedly played a role in white Americans stagnating life expectancies in recent years The increase in death in this segment of the population was great enough to affect life expectancy at birth for the whole group Elizabeth Arias aÂ statistician at the National Center for Health Statistics said according to the Times That is very unusual Unusual but not surprising Drug overdose deaths are on the rise according to the National Institute on Drug Abuse Its site offers data on overdose deaths for a variety of drugs between 2001 and 2014 Â For heroin benzodiazepines opioid painkillers and other prescription drugs overdose deaths were higher in 2014 than they were in any other year Meanwhile life expectancy among other demographics went up Black Americans expected lifespan rose from 75 5 years to 75 6 years according to the Times while Hispanic Americans rose from 81 6 to 81 8 Overall life expectancy among all Americans is 78 8 \n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Row 0 - guid of training set : \", val_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", val_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", val_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", val_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jIQvaQuqB6lT",
    "outputId": "29a3ac51-a936-4ddb-ad20-d7a414056f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yet', 'again', 'americas', 'drug', 'abuse', 'problem', 'takes', 'its', 'toll', 'white', 'americans', 'life', 'expect', '##ancy', 'declined', 'slightly', 'in', '2014', 'according', 'to', 'federal', 'data', 'reported', 'in', 'the', 'new', 'york', 'times', 'dropping', 'from', '78', '9', 'years', 'in', '2013', 'to', '78', '8', 'years', 'in', '2014', 'a', 'the', 'reason', 'a', 'rising', 'numbers', 'of', 'white', 'americans', 'area', 'dying', 'of', 'drug', 'overdose', '##s', 'particularly', 'among', 'those', '##a', 'in', 'their', 'mid', '20s', 'to', 'mid', '50', '##s', 'liver', 'disease', 'and', 'suicide', 'have', 'also', 'reportedly', 'played', 'a', 'role', 'in', 'white', 'americans', 'st', '##ag', '##nat', '##ing', 'life', 'expect', '##an', '##cies', 'in', 'recent', 'years', 'the', 'increase', 'in', 'death', 'in', 'this', 'segment', 'of', 'the', 'population', 'was', 'great', 'enough', 'to', 'affect', 'life', 'expect', '##ancy', 'at', 'birth', 'for', 'the', 'whole', 'group', 'elizabeth', 'arias', 'aa', 'stat', '##istic', '##ian', 'at', 'the', 'national', 'center', 'for', 'health', 'statistics', 'said', 'according', 'to', 'the', 'times', 'that', 'is', 'very', 'unusual', 'unusual', 'but', 'not', 'surprising', 'drug', 'overdose', 'deaths', 'are', 'on', 'the', 'rise', 'according', 'to', 'the', 'national', 'institute', 'on', 'drug', 'abuse', 'its', 'site', 'offers', 'data', 'on', 'overdose', 'deaths', 'for', 'a', 'variety', 'of', 'drugs', 'between', '2001', 'and', '2014', 'a', 'for', 'heroin', 'benz', '##od', '##ia', '##ze', '##pine', '##s', 'op', '##io', '##id', 'pain', '##kill', '##ers', 'and', 'other', 'prescription', 'drugs', 'overdose', 'deaths', 'were', 'higher', 'in', '2014', 'than', 'they', 'were', 'in', 'any', 'other', 'year', 'meanwhile', 'life', 'expect', '##ancy', 'among', 'other', 'demographics', 'went', 'up', 'black', 'americans', 'expected', 'lifespan', 'rose', 'from', '75', '5', 'years', 'to', '75', '6', 'years', 'according', 'to', 'the', 'times', 'while', 'hispanic', 'americans', 'rose', 'from', '81', '6', 'to', '81', '8', 'overall', 'life', 'expect', '##ancy', 'among', 'all', 'americans', 'is', '78', '8']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(val_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3BvJgvDQB6lY",
    "outputId": "bdc3af66-01cb-4639-e642-788cc6af309a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] yet again americas drug abuse problem takes its toll white americans life expect ##ancy declined slightly in 2014 according to federal data reported in the new york times dropping from 78 9 years in 2013 to 78 8 years in 2014 a the reason a rising numbers of white americans area dying of drug overdose ##s particularly among those ##a in their mid 20s to mid 50 ##s liver disease and suicide have also reportedly played a role in white americans st ##ag ##nat ##ing life expect ##an ##cies in recent years the increase in death in this segment of the population was great enough to affect life expect ##ancy at birth for the whole group elizabeth arias aa stat ##istic ##ian at the national center for health statistics said according to the times that is very unusual unusual but not surprising drug overdose deaths are on the rise according to the national institute on drug abuse its site offers data on overdose deaths for a variety of drugs between 2001 and 2014 a for heroin benz ##od ##ia ##ze ##pine ##s op ##io ##id pain ##kill ##ers and other prescription drugs overdose deaths were higher in 2014 than they were in any other year meanwhile life expect ##ancy among other demographics went up black americans expected lifespan rose from 75 5 years to 75 6 years according to the times while hispanic americans rose from 81 6 to 81 8 overall life expect ##ancy among all americans is 78 8 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] yet again americas drug abuse problem takes its toll white americans life expect ##ancy declined slightly in 2014 according to federal data reported in the new york times dropping from 78 9 years in 2013 to 78 8 years in 2014 a the reason a rising numbers of white americans area dying of drug overdose ##s particularly among those ##a in their mid 20s to mid 50 ##s liver disease and suicide have also reportedly played a role in white americans st ##ag ##nat ##ing life expect ##an ##cies in recent years the increase in death in this segment of the population was great enough to affect life expect ##ancy at birth for the whole group elizabeth arias aa stat ##istic ##ian at the national center for health statistics said according to the times that is very unusual unusual but not surprising drug overdose deaths are on the rise according to the national institute on drug abuse its site offers data on overdose deaths for a variety of drugs between 2001 and 2014 a for heroin benz ##od ##ia ##ze ##pine ##s op ##io ##id pain ##kill ##ers and other prescription drugs overdose deaths were higher in 2014 than they were in any other year meanwhile life expect ##ancy among other demographics went up black americans expected lifespan rose from 75 5 years to 75 6 years according to the times while hispanic americans rose from 81 6 to 81 8 overall life expect ##ancy among all americans is 78 8 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2664 2153 10925 4319 6905 3291 3138 2049 9565 2317 4841 2166 5987 11656 6430 3621 1999 2297 2429 2000 2976 2951 2988 1999 1996 2047 2259 2335 7510 2013 6275 1023 2086 1999 2286 2000 6275 1022 2086 1999 2297 1037 1996 3114 1037 4803 3616 1997 2317 4841 2181 5996 1997 4319 26641 2015 3391 2426 2216 2050 1999 2037 3054 27074 2000 3054 2753 2015 11290 4295 1998 5920 2031 2036 7283 2209 1037 2535 1999 2317 4841 2358 8490 19833 2075 2166 5987 2319 9243 1999 3522 2086 1996 3623 1999 2331 1999 2023 6903 1997 1996 2313 2001 2307 2438 2000 7461 2166 5987 11656 2012 4182 2005 1996 2878 2177 3870 25905 9779 28093 6553 2937 2012 1996 2120 2415 2005 2740 6747 2056 2429 2000 1996 2335 2008 2003 2200 5866 5866 2021 2025 11341 4319 26641 6677 2024 2006 1996 4125 2429 2000 1996 2120 2820 2006 4319 6905 2049 2609 4107 2951 2006 26641 6677 2005 1037 3528 1997 5850 2090 2541 1998 2297 1037 2005 19690 17770 7716 2401 4371 19265 2015 6728 3695 3593 3255 15872 2545 1998 2060 20422 5850 26641 6677 2020 3020 1999 2297 2084 2027 2020 1999 2151 2060 2095 5564 2166 5987 11656 2426 2060 28321 2253 2039 2304 4841 3517 26462 3123 2013 4293 1019 2086 2000 4293 1020 2086 2429 2000 1996 2335 2096 6696 4841 3123 2013 6282 1020 2000 6282 1022 3452 2166 5987 11656 2426 2035 4841 2003 6275 1022 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2664 2153 10925 4319 6905 3291 3138 2049 9565 2317 4841 2166 5987 11656 6430 3621 1999 2297 2429 2000 2976 2951 2988 1999 1996 2047 2259 2335 7510 2013 6275 1023 2086 1999 2286 2000 6275 1022 2086 1999 2297 1037 1996 3114 1037 4803 3616 1997 2317 4841 2181 5996 1997 4319 26641 2015 3391 2426 2216 2050 1999 2037 3054 27074 2000 3054 2753 2015 11290 4295 1998 5920 2031 2036 7283 2209 1037 2535 1999 2317 4841 2358 8490 19833 2075 2166 5987 2319 9243 1999 3522 2086 1996 3623 1999 2331 1999 2023 6903 1997 1996 2313 2001 2307 2438 2000 7461 2166 5987 11656 2012 4182 2005 1996 2878 2177 3870 25905 9779 28093 6553 2937 2012 1996 2120 2415 2005 2740 6747 2056 2429 2000 1996 2335 2008 2003 2200 5866 5866 2021 2025 11341 4319 26641 6677 2024 2006 1996 4125 2429 2000 1996 2120 2820 2006 4319 6905 2049 2609 4107 2951 2006 26641 6677 2005 1037 3528 1997 5850 2090 2541 1998 2297 1037 2005 19690 17770 7716 2401 4371 19265 2015 6728 3695 3593 3255 15872 2545 1998 2060 20422 5850 26641 6677 2020 3020 1999 2297 2084 2027 2020 1999 2151 2060 2095 5564 2166 5987 11656 2426 2060 28321 2253 2039 2304 4841 3517 26462 3123 2013 4293 1019 2086 2000 4293 1020 2086 2429 2000 1996 2335 2096 6696 4841 3123 2013 6282 1020 2000 6282 1022 3452 2166 5987 11656 2426 2035 4841 2003 6275 1022 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] a leader of the american family association which has loudly opposed target s transgender inclusive bathroom policy said monday that the group was sending men into women s restroom ##s in order to test the policy we ve already had people testing this going into targets and men going in to bathrooms there is absolutely no barrier sandy rios the director of government affairs for the af ##a told br ##eit ##bar ##t news daily the chief concern for the american family association is predators who will take advantage more than 1 1 million people have signed the af ##a s call to boycott target because of its policy allowing customers to use bathrooms and dressing rooms that correspond with their gender identity not the gender assigned to them at birth rios said that the policy would encourage men dressed like women to use the bathrooms and would create trauma for little girls i think the potential for sexual predators is just enormous she said lgbt ##q activists point out that there has been no increase in reports of sexual predators in bathrooms in the cities that have implemented trans inclusive bathroom policies and call this argument a red herring some of the largest organizations devoted to ending violence against women have also come out against the notion that such policies increase the likelihood of sex crimes calling the notion false rios called the defense of transgender rights an example of the mind ##less ridiculous madness of the radical left and encouraged listeners to sign the boycott petition against target write to charlotte alter at charlotte alter time com [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] a leader of the american family association which has loudly opposed target s transgender inclusive bathroom policy said monday that the group was sending men into women s restroom ##s in order to test the policy we ve already had people testing this going into targets and men going in to bathrooms there is absolutely no barrier sandy rios the director of government affairs for the af ##a told br ##eit ##bar ##t news daily the chief concern for the american family association is predators who will take advantage more than 1 1 million people have signed the af ##a s call to boycott target because of its policy allowing customers to use bathrooms and dressing rooms that correspond with their gender identity not the gender assigned to them at birth rios said that the policy would encourage men dressed like women to use the bathrooms and would create trauma for little girls i think the potential for sexual predators is just enormous she said lgbt ##q activists point out that there has been no increase in reports of sexual predators in bathrooms in the cities that have implemented trans inclusive bathroom policies and call this argument a red herring some of the largest organizations devoted to ending violence against women have also come out against the notion that such policies increase the likelihood of sex crimes calling the notion false rios called the defense of transgender rights an example of the mind ##less ridiculous madness of the radical left and encouraged listeners to sign the boycott petition against target write to charlotte alter at charlotte alter time com [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1037 3003 1997 1996 2137 2155 2523 2029 2038 9928 4941 4539 1055 16824 18678 5723 3343 2056 6928 2008 1996 2177 2001 6016 2273 2046 2308 1055 28249 2015 1999 2344 2000 3231 1996 3343 2057 2310 2525 2018 2111 5604 2023 2183 2046 7889 1998 2273 2183 1999 2000 28942 2045 2003 7078 2053 8803 7525 25836 1996 2472 1997 2231 3821 2005 1996 21358 2050 2409 7987 20175 8237 2102 2739 3679 1996 2708 5142 2005 1996 2137 2155 2523 2003 12630 2040 2097 2202 5056 2062 2084 1015 1015 2454 2111 2031 2772 1996 21358 2050 1055 2655 2000 17757 4539 2138 1997 2049 3343 4352 6304 2000 2224 28942 1998 11225 4734 2008 17254 2007 2037 5907 4767 2025 1996 5907 4137 2000 2068 2012 4182 25836 2056 2008 1996 3343 2052 8627 2273 5102 2066 2308 2000 2224 1996 28942 1998 2052 3443 12603 2005 2210 3057 1045 2228 1996 4022 2005 4424 12630 2003 2074 8216 2016 2056 12010 4160 10134 2391 2041 2008 2045 2038 2042 2053 3623 1999 4311 1997 4424 12630 1999 28942 1999 1996 3655 2008 2031 7528 9099 18678 5723 6043 1998 2655 2023 6685 1037 2417 22103 2070 1997 1996 2922 4411 7422 2000 4566 4808 2114 2308 2031 2036 2272 2041 2114 1996 9366 2008 2107 6043 3623 1996 16593 1997 3348 6997 4214 1996 9366 6270 25836 2170 1996 3639 1997 16824 2916 2019 2742 1997 1996 2568 3238 9951 12013 1997 1996 7490 2187 1998 6628 13810 2000 3696 1996 17757 9964 2114 4539 4339 2000 5904 11477 2012 5904 11477 2051 4012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1037 3003 1997 1996 2137 2155 2523 2029 2038 9928 4941 4539 1055 16824 18678 5723 3343 2056 6928 2008 1996 2177 2001 6016 2273 2046 2308 1055 28249 2015 1999 2344 2000 3231 1996 3343 2057 2310 2525 2018 2111 5604 2023 2183 2046 7889 1998 2273 2183 1999 2000 28942 2045 2003 7078 2053 8803 7525 25836 1996 2472 1997 2231 3821 2005 1996 21358 2050 2409 7987 20175 8237 2102 2739 3679 1996 2708 5142 2005 1996 2137 2155 2523 2003 12630 2040 2097 2202 5056 2062 2084 1015 1015 2454 2111 2031 2772 1996 21358 2050 1055 2655 2000 17757 4539 2138 1997 2049 3343 4352 6304 2000 2224 28942 1998 11225 4734 2008 17254 2007 2037 5907 4767 2025 1996 5907 4137 2000 2068 2012 4182 25836 2056 2008 1996 3343 2052 8627 2273 5102 2066 2308 2000 2224 1996 28942 1998 2052 3443 12603 2005 2210 3057 1045 2228 1996 4022 2005 4424 12630 2003 2074 8216 2016 2056 12010 4160 10134 2391 2041 2008 2045 2038 2042 2053 3623 1999 4311 1997 4424 12630 1999 28942 1999 1996 3655 2008 2031 7528 9099 18678 5723 6043 1998 2655 2023 6685 1037 2417 22103 2070 1997 1996 2922 4411 7422 2000 4566 4808 2114 2308 2031 2036 2272 2041 2114 1996 9366 2008 2107 6043 3623 1996 16593 1997 3348 6997 4214 1996 9366 6270 25836 2170 1996 3639 1997 16824 2916 2019 2742 1997 1996 2568 3238 9951 12013 1997 1996 7490 2187 1998 6628 13810 2000 3696 1996 17757 9964 2114 4539 4339 2000 5904 11477 2012 5904 11477 2051 4012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] donald trump s campaign chairman paul mana ##fort denied a new york times report that political leaders in ukraine ear ##mark ##ed millions in undisclosed cash for him the times reported that the political party of ukraine s pro russian former president viktor yan ##uk ##ov ##ych set aside 12 7 million in undisclosed payments for the campaign operative mana ##fort responded to the report in a statement sent to nbc news on monday calling it un ##founded silly and non ##sen ##sic ##al i have never received a single off the books cash payment as falsely reported by the new york times nor have i ever done work for the governments of ukraine or russia mana ##fort said adding that any payments he did receive overseas were for his entire political team this suggestion that i accepted cash payments is un ##founded silly and non ##sen ##sic ##al the times report said anti corruption officials are investigating the ear ##mark ##ed payments which were recorded on a secret ledger though they have not determined whether or not mana ##fort actually received any cash mana ##fort said his work in ukraine ended after the 2014 parliamentary elections the hillary clinton campaign has also responded to the report saying the report raises questions about the trump campaign s ties to russia given the pro putin policy stance ##s adopted by donald trump and the recent russian government hacking and disclosure of democratic party records donald trump has a responsibility to disclose campaign chair paul mana ##fort s and all other campaign employees and advisers ties to russia and pro k ##rem ##lin entities the statement reads read the times story here contact us at editors time com [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] donald trump s campaign chairman paul mana ##fort denied a new york times report that political leaders in ukraine ear ##mark ##ed millions in undisclosed cash for him the times reported that the political party of ukraine s pro russian former president viktor yan ##uk ##ov ##ych set aside 12 7 million in undisclosed payments for the campaign operative mana ##fort responded to the report in a statement sent to nbc news on monday calling it un ##founded silly and non ##sen ##sic ##al i have never received a single off the books cash payment as falsely reported by the new york times nor have i ever done work for the governments of ukraine or russia mana ##fort said adding that any payments he did receive overseas were for his entire political team this suggestion that i accepted cash payments is un ##founded silly and non ##sen ##sic ##al the times report said anti corruption officials are investigating the ear ##mark ##ed payments which were recorded on a secret ledger though they have not determined whether or not mana ##fort actually received any cash mana ##fort said his work in ukraine ended after the 2014 parliamentary elections the hillary clinton campaign has also responded to the report saying the report raises questions about the trump campaign s ties to russia given the pro putin policy stance ##s adopted by donald trump and the recent russian government hacking and disclosure of democratic party records donald trump has a responsibility to disclose campaign chair paul mana ##fort s and all other campaign employees and advisers ties to russia and pro k ##rem ##lin entities the statement reads read the times story here contact us at editors time com [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6221 8398 1055 3049 3472 2703 24951 13028 6380 1037 2047 2259 2335 3189 2008 2576 4177 1999 5924 4540 10665 2098 8817 1999 18206 5356 2005 2032 1996 2335 2988 2008 1996 2576 2283 1997 5924 1055 4013 2845 2280 2343 13489 13619 6968 4492 17994 2275 4998 2260 1021 2454 1999 18206 10504 2005 1996 3049 12160 24951 13028 5838 2000 1996 3189 1999 1037 4861 2741 2000 6788 2739 2006 6928 4214 2009 4895 21001 10021 1998 2512 5054 19570 2389 1045 2031 2196 2363 1037 2309 2125 1996 2808 5356 7909 2004 23123 2988 2011 1996 2047 2259 2335 4496 2031 1045 2412 2589 2147 2005 1996 6867 1997 5924 2030 3607 24951 13028 2056 5815 2008 2151 10504 2002 2106 4374 6931 2020 2005 2010 2972 2576 2136 2023 10293 2008 1045 3970 5356 10504 2003 4895 21001 10021 1998 2512 5054 19570 2389 1996 2335 3189 2056 3424 7897 4584 2024 11538 1996 4540 10665 2098 10504 2029 2020 2680 2006 1037 3595 27106 2295 2027 2031 2025 4340 3251 2030 2025 24951 13028 2941 2363 2151 5356 24951 13028 2056 2010 2147 1999 5924 3092 2044 1996 2297 5768 3864 1996 18520 7207 3049 2038 2036 5838 2000 1996 3189 3038 1996 3189 13275 3980 2055 1996 8398 3049 1055 7208 2000 3607 2445 1996 4013 22072 3343 11032 2015 4233 2011 6221 8398 1998 1996 3522 2845 2231 23707 1998 19380 1997 3537 2283 2636 6221 8398 2038 1037 5368 2000 26056 3049 3242 2703 24951 13028 1055 1998 2035 2060 3049 5126 1998 24205 7208 2000 3607 1998 4013 1047 28578 4115 11422 1996 4861 9631 3191 1996 2335 2466 2182 3967 2149 2012 10195 2051 4012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6221 8398 1055 3049 3472 2703 24951 13028 6380 1037 2047 2259 2335 3189 2008 2576 4177 1999 5924 4540 10665 2098 8817 1999 18206 5356 2005 2032 1996 2335 2988 2008 1996 2576 2283 1997 5924 1055 4013 2845 2280 2343 13489 13619 6968 4492 17994 2275 4998 2260 1021 2454 1999 18206 10504 2005 1996 3049 12160 24951 13028 5838 2000 1996 3189 1999 1037 4861 2741 2000 6788 2739 2006 6928 4214 2009 4895 21001 10021 1998 2512 5054 19570 2389 1045 2031 2196 2363 1037 2309 2125 1996 2808 5356 7909 2004 23123 2988 2011 1996 2047 2259 2335 4496 2031 1045 2412 2589 2147 2005 1996 6867 1997 5924 2030 3607 24951 13028 2056 5815 2008 2151 10504 2002 2106 4374 6931 2020 2005 2010 2972 2576 2136 2023 10293 2008 1045 3970 5356 10504 2003 4895 21001 10021 1998 2512 5054 19570 2389 1996 2335 3189 2056 3424 7897 4584 2024 11538 1996 4540 10665 2098 10504 2029 2020 2680 2006 1037 3595 27106 2295 2027 2031 2025 4340 3251 2030 2025 24951 13028 2941 2363 2151 5356 24951 13028 2056 2010 2147 1999 5924 3092 2044 1996 2297 5768 3864 1996 18520 7207 3049 2038 2036 5838 2000 1996 3189 3038 1996 3189 13275 3980 2055 1996 8398 3049 1055 7208 2000 3607 2445 1996 4013 22072 3343 11032 2015 4233 2011 6221 8398 1998 1996 3522 2845 2231 23707 1998 19380 1997 3537 2283 2636 6221 8398 2038 1037 5368 2000 26056 3049 3242 2703 24951 13028 1055 1998 2035 2060 3049 5126 1998 24205 7208 2000 3607 1998 4013 1047 28578 4115 11422 1996 4861 9631 3191 1996 2335 2466 2182 3967 2149 2012 10195 2051 4012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] sarah mcbride pee ##d the other day but it wasn t just any trip to the bathroom sarah is a transgender woman and she chose to use a women s restroom in north carolina in a government building no less sarah s powerful act comes after north carolina put h ##b ##2 into effect a law that requires bathroom go ##ers to use the restroom of their gender at birth consequently disc ##rim ##inating against many in the lgbt community the 25 year old trans woman and activist is the communications manager for lgbt progress at american progress and she was recently in north carolina to speak to trans people about how the law was affecting their lives then after a meeting at the mecklenburg government center on thursday she went to the ladies room the response on facebook was overwhelming garner ##ing 38 000 reactions and 13 80 ##4 shares at the time of publication i m sorry for my state sarah i m hoping very much they see the error of their ways and repeal this piece of garbage soon thank you for breaking the rules to illustrate how stupid this whole thing is wrote one person proud to pee next to you anytime repeal ##h ##b ##2 wrote another this isn t about abstract issues or fears sarah told buzz ##fe ##ed this is about real people being able to access the bathroom and being able to participate in public life i m a person just trying to make it through my day she added in her statement regardless of how i look i shouldn t be afraid of discrimination or violence [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] sarah mcbride pee ##d the other day but it wasn t just any trip to the bathroom sarah is a transgender woman and she chose to use a women s restroom in north carolina in a government building no less sarah s powerful act comes after north carolina put h ##b ##2 into effect a law that requires bathroom go ##ers to use the restroom of their gender at birth consequently disc ##rim ##inating against many in the lgbt community the 25 year old trans woman and activist is the communications manager for lgbt progress at american progress and she was recently in north carolina to speak to trans people about how the law was affecting their lives then after a meeting at the mecklenburg government center on thursday she went to the ladies room the response on facebook was overwhelming garner ##ing 38 000 reactions and 13 80 ##4 shares at the time of publication i m sorry for my state sarah i m hoping very much they see the error of their ways and repeal this piece of garbage soon thank you for breaking the rules to illustrate how stupid this whole thing is wrote one person proud to pee next to you anytime repeal ##h ##b ##2 wrote another this isn t about abstract issues or fears sarah told buzz ##fe ##ed this is about real people being able to access the bathroom and being able to participate in public life i m a person just trying to make it through my day she added in her statement regardless of how i look i shouldn t be afraid of discrimination or violence [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4532 18958 21392 2094 1996 2060 2154 2021 2009 2347 1056 2074 2151 4440 2000 1996 5723 4532 2003 1037 16824 2450 1998 2016 4900 2000 2224 1037 2308 1055 28249 1999 2167 3792 1999 1037 2231 2311 2053 2625 4532 1055 3928 2552 3310 2044 2167 3792 2404 1044 2497 2475 2046 3466 1037 2375 2008 5942 5723 2175 2545 2000 2224 1996 28249 1997 2037 5907 2012 4182 8821 5860 20026 19185 2114 2116 1999 1996 12010 2451 1996 2423 2095 2214 9099 2450 1998 7423 2003 1996 4806 3208 2005 12010 5082 2012 2137 5082 1998 2016 2001 3728 1999 2167 3792 2000 3713 2000 9099 2111 2055 2129 1996 2375 2001 12473 2037 3268 2059 2044 1037 3116 2012 1996 22007 2231 2415 2006 9432 2016 2253 2000 1996 6456 2282 1996 3433 2006 9130 2001 10827 18661 2075 4229 2199 9597 1998 2410 3770 2549 6661 2012 1996 2051 1997 4772 1045 1049 3374 2005 2026 2110 4532 1045 1049 5327 2200 2172 2027 2156 1996 7561 1997 2037 3971 1998 21825 2023 3538 1997 13044 2574 4067 2017 2005 4911 1996 3513 2000 19141 2129 5236 2023 2878 2518 2003 2626 2028 2711 7098 2000 21392 2279 2000 2017 15933 21825 2232 2497 2475 2626 2178 2023 3475 1056 2055 10061 3314 2030 10069 4532 2409 12610 7959 2098 2023 2003 2055 2613 2111 2108 2583 2000 3229 1996 5723 1998 2108 2583 2000 5589 1999 2270 2166 1045 1049 1037 2711 2074 2667 2000 2191 2009 2083 2026 2154 2016 2794 1999 2014 4861 7539 1997 2129 1045 2298 1045 5807 1056 2022 4452 1997 9147 2030 4808 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4532 18958 21392 2094 1996 2060 2154 2021 2009 2347 1056 2074 2151 4440 2000 1996 5723 4532 2003 1037 16824 2450 1998 2016 4900 2000 2224 1037 2308 1055 28249 1999 2167 3792 1999 1037 2231 2311 2053 2625 4532 1055 3928 2552 3310 2044 2167 3792 2404 1044 2497 2475 2046 3466 1037 2375 2008 5942 5723 2175 2545 2000 2224 1996 28249 1997 2037 5907 2012 4182 8821 5860 20026 19185 2114 2116 1999 1996 12010 2451 1996 2423 2095 2214 9099 2450 1998 7423 2003 1996 4806 3208 2005 12010 5082 2012 2137 5082 1998 2016 2001 3728 1999 2167 3792 2000 3713 2000 9099 2111 2055 2129 1996 2375 2001 12473 2037 3268 2059 2044 1037 3116 2012 1996 22007 2231 2415 2006 9432 2016 2253 2000 1996 6456 2282 1996 3433 2006 9130 2001 10827 18661 2075 4229 2199 9597 1998 2410 3770 2549 6661 2012 1996 2051 1997 4772 1045 1049 3374 2005 2026 2110 4532 1045 1049 5327 2200 2172 2027 2156 1996 7561 1997 2037 3971 1998 21825 2023 3538 1997 13044 2574 4067 2017 2005 4911 1996 3513 2000 19141 2129 5236 2023 2878 2518 2003 2626 2028 2711 7098 2000 21392 2279 2000 2017 15933 21825 2232 2497 2475 2626 2178 2023 3475 1056 2055 10061 3314 2030 10069 4532 2409 12610 7959 2098 2023 2003 2055 2613 2111 2108 2583 2000 3229 1996 5723 1998 2108 2583 2000 5589 1999 2270 2166 1045 1049 1037 2711 2074 2667 2000 2191 2009 2083 2026 2154 2016 2794 1999 2014 4861 7539 1997 2129 1045 2298 1045 5807 1056 2022 4452 1997 9147 2030 4808 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] troll ##ing can take many forms and on a recent airing of fox news the ore ##illy factor host bill ore ##illy opted for the direct approach on a mission to ostensibly figure out why in his words college students these days are very sensitive individuals ore ##illy sent correspondent ##a jesse ##a watt ##ers to princeton university to ask students if they were offended by the word ghetto when someone says ghetto how do you feel about that watt ##ers asked a black student in the segments opening dialogue a i feel like they should be more careful in their choice of words the student responded a things went on from there watt ##ers ended the segment on a light note with ore ##illy laughing about the experience they didn ##t seem as crazy as some of these other college kids who start to cry when they see donald trump ##s name chalk ##ed on a wall or something said ore ##illy they actually took you seriously that ##s the biggest mistake they made watt ##ers replied a lately race has been an especially heated topic on the ivy league campus ##a after a special committee decided to keep ##a former u s a and former princeton university a president woodrow wilson ##s name on the ##a school of public and international affairs saying ##a in a statement that they would work to create a more multi ##face ##ted understanding and representation of wilson on campus princeton ##s black justice league led the charge to remove wilson ##s name since september citing wilson ##sa historically racist and particularly his pro segregation stance ##s read the leagues response to the decision here watch the whole segment here [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] troll ##ing can take many forms and on a recent airing of fox news the ore ##illy factor host bill ore ##illy opted for the direct approach on a mission to ostensibly figure out why in his words college students these days are very sensitive individuals ore ##illy sent correspondent ##a jesse ##a watt ##ers to princeton university to ask students if they were offended by the word ghetto when someone says ghetto how do you feel about that watt ##ers asked a black student in the segments opening dialogue a i feel like they should be more careful in their choice of words the student responded a things went on from there watt ##ers ended the segment on a light note with ore ##illy laughing about the experience they didn ##t seem as crazy as some of these other college kids who start to cry when they see donald trump ##s name chalk ##ed on a wall or something said ore ##illy they actually took you seriously that ##s the biggest mistake they made watt ##ers replied a lately race has been an especially heated topic on the ivy league campus ##a after a special committee decided to keep ##a former u s a and former princeton university a president woodrow wilson ##s name on the ##a school of public and international affairs saying ##a in a statement that they would work to create a more multi ##face ##ted understanding and representation of wilson on campus princeton ##s black justice league led the charge to remove wilson ##s name since september citing wilson ##sa historically racist and particularly his pro segregation stance ##s read the leagues response to the decision here watch the whole segment here [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 18792 2075 2064 2202 2116 3596 1998 2006 1037 3522 10499 1997 4419 2739 1996 10848 20577 5387 3677 3021 10848 20577 12132 2005 1996 3622 3921 2006 1037 3260 2000 23734 3275 2041 2339 1999 2010 2616 2267 2493 2122 2420 2024 2200 7591 3633 10848 20577 2741 11370 2050 7627 2050 15231 2545 2000 9173 2118 2000 3198 2493 2065 2027 2020 15807 2011 1996 2773 17276 2043 2619 2758 17276 2129 2079 2017 2514 2055 2008 15231 2545 2356 1037 2304 3076 1999 1996 9214 3098 7982 1037 1045 2514 2066 2027 2323 2022 2062 6176 1999 2037 3601 1997 2616 1996 3076 5838 1037 2477 2253 2006 2013 2045 15231 2545 3092 1996 6903 2006 1037 2422 3602 2007 10848 20577 5870 2055 1996 3325 2027 2134 2102 4025 2004 4689 2004 2070 1997 2122 2060 2267 4268 2040 2707 2000 5390 2043 2027 2156 6221 8398 2015 2171 16833 2098 2006 1037 2813 2030 2242 2056 10848 20577 2027 2941 2165 2017 5667 2008 2015 1996 5221 6707 2027 2081 15231 2545 3880 1037 9906 2679 2038 2042 2019 2926 9685 8476 2006 1996 7768 2223 3721 2050 2044 1037 2569 2837 2787 2000 2562 2050 2280 1057 1055 1037 1998 2280 9173 2118 1037 2343 23954 4267 2015 2171 2006 1996 2050 2082 1997 2270 1998 2248 3821 3038 2050 1999 1037 4861 2008 2027 2052 2147 2000 3443 1037 2062 4800 12172 3064 4824 1998 6630 1997 4267 2006 3721 9173 2015 2304 3425 2223 2419 1996 3715 2000 6366 4267 2015 2171 2144 2244 8951 4267 3736 7145 16939 1998 3391 2010 4013 18771 11032 2015 3191 1996 8121 3433 2000 1996 3247 2182 3422 1996 2878 6903 2182 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 18792 2075 2064 2202 2116 3596 1998 2006 1037 3522 10499 1997 4419 2739 1996 10848 20577 5387 3677 3021 10848 20577 12132 2005 1996 3622 3921 2006 1037 3260 2000 23734 3275 2041 2339 1999 2010 2616 2267 2493 2122 2420 2024 2200 7591 3633 10848 20577 2741 11370 2050 7627 2050 15231 2545 2000 9173 2118 2000 3198 2493 2065 2027 2020 15807 2011 1996 2773 17276 2043 2619 2758 17276 2129 2079 2017 2514 2055 2008 15231 2545 2356 1037 2304 3076 1999 1996 9214 3098 7982 1037 1045 2514 2066 2027 2323 2022 2062 6176 1999 2037 3601 1997 2616 1996 3076 5838 1037 2477 2253 2006 2013 2045 15231 2545 3092 1996 6903 2006 1037 2422 3602 2007 10848 20577 5870 2055 1996 3325 2027 2134 2102 4025 2004 4689 2004 2070 1997 2122 2060 2267 4268 2040 2707 2000 5390 2043 2027 2156 6221 8398 2015 2171 16833 2098 2006 1037 2813 2030 2242 2056 10848 20577 2027 2941 2165 2017 5667 2008 2015 1996 5221 6707 2027 2081 15231 2545 3880 1037 9906 2679 2038 2042 2019 2926 9685 8476 2006 1996 7768 2223 3721 2050 2044 1037 2569 2837 2787 2000 2562 2050 2280 1057 1055 1037 1998 2280 9173 2118 1037 2343 23954 4267 2015 2171 2006 1996 2050 2082 1997 2270 1998 2248 3821 3038 2050 1999 1037 4861 2008 2027 2052 2147 2000 3443 1037 2062 4800 12172 3064 4824 1998 6630 1997 4267 2006 3721 9173 2015 2304 3425 2223 2419 1996 3715 2000 6366 4267 2015 2171 2144 2244 8951 4267 3736 7145 16939 1998 3391 2010 4013 18771 11032 2015 3191 1996 8121 3433 2000 1996 3247 2182 3422 1996 2878 6903 2182 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0.0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "OcVvQk4BB6lb",
    "outputId": "ac689cf0-0aba-4cbe-e0c9-7f5a401058c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :  Yet again Americas drug abuse problem takes its toll White Americans life expectancy declined slightly in 2014 according to federal data reported in the New York Times dropping from 78 9 years in 2013 to 78 8 years in 2014 Â The reason Â Rising numbers of white Americans areÂ dying of drug overdoses particularly among thoseÂ in their mid 20s to mid 50s Liver disease and suicide have also reportedly played a role in white Americans stagnating life expectancies in recent years The increase in death in this segment of the population was great enough to affect life expectancy at birth for the whole group Elizabeth Arias aÂ statistician at the National Center for Health Statistics said according to the Times That is very unusual Unusual but not surprising Drug overdose deaths are on the rise according to the National Institute on Drug Abuse Its site offers data on overdose deaths for a variety of drugs between 2001 and 2014 Â For heroin benzodiazepines opioid painkillers and other prescription drugs overdose deaths were higher in 2014 than they were in any other year Meanwhile life expectancy among other demographics went up Black Americans expected lifespan rose from 75 5 years to 75 6 years according to the Times while Hispanic Americans rose from 81 6 to 81 8 Overall life expectancy among all Americans is 78 8 \n",
      "------------------------------\n",
      "Tokens :  ['yet', 'again', 'americas', 'drug', 'abuse', 'problem', 'takes', 'its', 'toll', 'white', 'americans', 'life', 'expect', '##ancy', 'declined', 'slightly', 'in', '2014', 'according', 'to', 'federal', 'data', 'reported', 'in', 'the', 'new', 'york', 'times', 'dropping', 'from', '78', '9', 'years', 'in', '2013', 'to', '78', '8', 'years', 'in', '2014', 'a', 'the', 'reason', 'a', 'rising', 'numbers', 'of', 'white', 'americans', 'area', 'dying', 'of', 'drug', 'overdose', '##s', 'particularly', 'among', 'those', '##a', 'in', 'their', 'mid', '20s', 'to', 'mid', '50', '##s', 'liver', 'disease', 'and', 'suicide', 'have', 'also', 'reportedly', 'played', 'a', 'role', 'in', 'white', 'americans', 'st', '##ag', '##nat', '##ing', 'life', 'expect', '##an', '##cies', 'in', 'recent', 'years', 'the', 'increase', 'in', 'death', 'in', 'this', 'segment', 'of', 'the', 'population', 'was', 'great', 'enough', 'to', 'affect', 'life', 'expect', '##ancy', 'at', 'birth', 'for', 'the', 'whole', 'group', 'elizabeth', 'arias', 'aa', 'stat', '##istic', '##ian', 'at', 'the', 'national', 'center', 'for', 'health', 'statistics', 'said', 'according', 'to', 'the', 'times', 'that', 'is', 'very', 'unusual', 'unusual', 'but', 'not', 'surprising', 'drug', 'overdose', 'deaths', 'are', 'on', 'the', 'rise', 'according', 'to', 'the', 'national', 'institute', 'on', 'drug', 'abuse', 'its', 'site', 'offers', 'data', 'on', 'overdose', 'deaths', 'for', 'a', 'variety', 'of', 'drugs', 'between', '2001', 'and', '2014', 'a', 'for', 'heroin', 'benz', '##od', '##ia', '##ze', '##pine', '##s', 'op', '##io', '##id', 'pain', '##kill', '##ers', 'and', 'other', 'prescription', 'drugs', 'overdose', 'deaths', 'were', 'higher', 'in', '2014', 'than', 'they', 'were', 'in', 'any', 'other', 'year', 'meanwhile', 'life', 'expect', '##ancy', 'among', 'other', 'demographics', 'went', 'up', 'black', 'americans', 'expected', 'lifespan', 'rose', 'from', '75', '5', 'years', 'to', '75', '6', 'years', 'according', 'to', 'the', 'times', 'while', 'hispanic', 'americans', 'rose', 'from', '81', '6', 'to', '81', '8', 'overall', 'life', 'expect', '##ancy', 'among', 'all', 'americans', 'is', '78', '8']\n",
      "------------------------------\n",
      "Input IDs :  [101, 2664, 2153, 10925, 4319, 6905, 3291, 3138, 2049, 9565, 2317, 4841, 2166, 5987, 11656, 6430, 3621, 1999, 2297, 2429, 2000, 2976, 2951, 2988, 1999, 1996, 2047, 2259, 2335, 7510, 2013, 6275, 1023, 2086, 1999, 2286, 2000, 6275, 1022, 2086, 1999, 2297, 1037, 1996, 3114, 1037, 4803, 3616, 1997, 2317, 4841, 2181, 5996, 1997, 4319, 26641, 2015, 3391, 2426, 2216, 2050, 1999, 2037, 3054, 27074, 2000, 3054, 2753, 2015, 11290, 4295, 1998, 5920, 2031, 2036, 7283, 2209, 1037, 2535, 1999, 2317, 4841, 2358, 8490, 19833, 2075, 2166, 5987, 2319, 9243, 1999, 3522, 2086, 1996, 3623, 1999, 2331, 1999, 2023, 6903, 1997, 1996, 2313, 2001, 2307, 2438, 2000, 7461, 2166, 5987, 11656, 2012, 4182, 2005, 1996, 2878, 2177, 3870, 25905, 9779, 28093, 6553, 2937, 2012, 1996, 2120, 2415, 2005, 2740, 6747, 2056, 2429, 2000, 1996, 2335, 2008, 2003, 2200, 5866, 5866, 2021, 2025, 11341, 4319, 26641, 6677, 2024, 2006, 1996, 4125, 2429, 2000, 1996, 2120, 2820, 2006, 4319, 6905, 2049, 2609, 4107, 2951, 2006, 26641, 6677, 2005, 1037, 3528, 1997, 5850, 2090, 2541, 1998, 2297, 1037, 2005, 19690, 17770, 7716, 2401, 4371, 19265, 2015, 6728, 3695, 3593, 3255, 15872, 2545, 1998, 2060, 20422, 5850, 26641, 6677, 2020, 3020, 1999, 2297, 2084, 2027, 2020, 1999, 2151, 2060, 2095, 5564, 2166, 5987, 11656, 2426, 2060, 28321, 2253, 2039, 2304, 4841, 3517, 26462, 3123, 2013, 4293, 1019, 2086, 2000, 4293, 1020, 2086, 2429, 2000, 1996, 2335, 2096, 6696, 4841, 3123, 2013, 6282, 1020, 2000, 6282, 1022, 3452, 2166, 5987, 11656, 2426, 2035, 4841, 2003, 6275, 1022, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"Sentence : \", val_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(val_InputExamples.iloc[0].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", val_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", val_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", val_features[0].segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJQ292GvB6ld"
   },
   "source": [
    "# Val Input Fn BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m_HQRehsB6lq"
   },
   "outputs": [],
   "source": [
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3dwBuzpiB6lt"
   },
   "source": [
    "# BERT: Evaluating on Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TadkXZ6YB6lw"
   },
   "source": [
    "The accuracy for the fine tuned BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "hwW_A_ZrB6lw",
    "outputId": "7b3919fb-7f75-466d-cae0-b3113aa11708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-28T00:09:55Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-28T00:09:55Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-28-00:10:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-28-00:10:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2339: eval_accuracy = 0.41153845, false_negatives = 69.0, false_positives = 31.0, global_step = 2339, loss = 1.1391656, true_negatives = 17.0, true_positives = 143.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2339: eval_accuracy = 0.41153845, false_negatives = 69.0, false_positives = 31.0, global_step = 2339, loss = 1.1391656, true_negatives = 17.0, true_positives = 143.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2339: /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2339: /bert_news_category/model.ckpt-2339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.41153845,\n",
       " 'false_negatives': 69.0,\n",
       " 'false_positives': 31.0,\n",
       " 'global_step': 2339,\n",
       " 'loss': 1.1391656,\n",
       " 'true_negatives': 17.0,\n",
       " 'true_positives': 143.0}"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubX4mo7ahbZI"
   },
   "source": [
    "# Using BERT Vector Transformations in LSTM (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7B114QMlVwMm"
   },
   "outputs": [],
   "source": [
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WKpDMg-nV-yZ",
    "outputId": "1faec426-40a4-48ab-bddd-7af896762af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjRdLdqj-mpo",
    "outputId": "9a4f908a-275d-4462-bc64-37d1711b7eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45478, 2), (11389, 2))"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4Q7Ih3nmNXh"
   },
   "source": [
    "Now extracting the representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "2z3hwrsaWECM",
    "outputId": "e067fc50-8e68-4197-f726-2e9eb069b731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 1min 1s, total: 4min 1s\n",
      "Wall time: 21min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))\n",
    "tr_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bw6nDeP2WR_u",
    "outputId": "2f3acbdc-f79c-4f52-87ea-0d66578756fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 s, sys: 15.5 s, total: 1min 3s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n",
    "val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BQbVWlptWUGE",
    "outputId": "b5246c6a-4ca2-4304-d1cc-b5be6da34e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11389, 768), (45478, 768))"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_emb.shape, tr_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbIDKTbw8lOt"
   },
   "source": [
    "and make the dataset for train and val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tFV-0AQw749e"
   },
   "outputs": [],
   "source": [
    "index_l = train_df.index\n",
    "val_index_l = val_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4bBZiJG6hEdU",
    "outputId": "bab527ab-488c-4f41-974e-0478adab253f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45478"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Oq2tpvrUkyoa",
    "outputId": "13c1c337-ee1b-4af8-8699-f66d12e4a052"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.69760984, -0.23813823, 0.12087678, 0.4723...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.2590735, 0.41492596, 0.9647107, 0.1478490...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.66147554, 0.13714084, 0.9400091, 0.301015...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.45993647, -0.17232634, 0.5241977, 0.26222...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.34092507, 0.16185749, 0.93247384, -0.31810...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.69760984, -0.23813823, 0.12087678, 0.4723...      3\n",
       "1  [[-0.2590735, 0.41492596, 0.9647107, 0.1478490...      3\n",
       "2  [[-0.66147554, 0.13714084, 0.9400091, 0.301015...      1\n",
       "3  [[-0.45993647, -0.17232634, 0.5241977, 0.26222...      1\n",
       "4  [[0.34092507, 0.16185749, 0.93247384, -0.31810...      0"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train_df.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "cnjcaZHqk6rf",
    "outputId": "0b2b88eb-c89e-4ffe-f822-01193084321a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.4948553, 0.2777687, 0.9994403, -0.6164913,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.123172425, -0.19518024, 0.961045, -0.25922...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.30272684, 0.47506917, 0.99982846, -0.73929...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.77450377, -0.010807645, 0.88968754, 0.691...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.5057215, -0.0024662102, 0.9497135, 0.2925...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.4948553, 0.2777687, 0.9994403, -0.6164913,...      2\n",
       "1  [[0.123172425, -0.19518024, 0.961045, -0.25922...      2\n",
       "2  [[0.30272684, 0.47506917, 0.99982846, -0.73929...      2\n",
       "3  [[-0.77450377, -0.010807645, 0.88968754, 0.691...      4\n",
       "4  [[-0.5057215, -0.0024662102, 0.9497135, 0.2925...      3"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val_df.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VMDe3KvcIM5q"
   },
   "outputs": [],
   "source": [
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzIznwgQiD6x"
   },
   "source": [
    "# LSTM: Creating the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "260A5YvElD2D",
    "outputId": "3f2cf359-d189-47d1-d149-cbf51a42f5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 350,785\n",
      "Trainable params: 350,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_SR7cUPRlvNg",
    "outputId": "f361f487-b0e1-4613-aa9f-a1abea6d9f8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45480, 2), (3757, 2), (2506, 2))"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3z6awGncq9wB"
   },
   "source": [
    "The generator functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5vAf9GmGlSnm"
   },
   "outputs": [],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "batch_size = 30\n",
    "batches_per_epoch =  1516\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ezFSiXl_meEo"
   },
   "outputs": [],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "batch_size_val = 17\n",
    "batches_per_epoch_val = 221\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVw-FcrrjEMW"
   },
   "source": [
    "# LSTM Final Model: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FsT12SSbmzAl"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "colab_type": "code",
    "id": "bDysNyfIm7Em",
    "outputId": "3f352953-20c4-4e56-9e77-c5ca1e6b1392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.9528 - acc: 0.6301 - val_loss: 1.0363 - val_acc: 0.5337\n",
      "Epoch 2/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.9280 - acc: 0.6371 - val_loss: 1.0373 - val_acc: 0.5374\n",
      "Epoch 3/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.9181 - acc: 0.6395 - val_loss: 1.0762 - val_acc: 0.5369\n",
      "Epoch 4/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.9110 - acc: 0.6406 - val_loss: 1.1004 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 5/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.9023 - acc: 0.6421 - val_loss: 1.0876 - val_acc: 0.5419\n",
      "Epoch 6/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8946 - acc: 0.6449 - val_loss: 1.0968 - val_acc: 0.5419\n",
      "Epoch 7/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8883 - acc: 0.6450 - val_loss: 1.1108 - val_acc: 0.5390\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 8/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8780 - acc: 0.6480 - val_loss: 1.1278 - val_acc: 0.5430\n",
      "Epoch 9/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8711 - acc: 0.6495 - val_loss: 1.0096 - val_acc: 0.5369\n",
      "Epoch 10/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8645 - acc: 0.6508 - val_loss: 1.0441 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "Epoch 11/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8545 - acc: 0.6535 - val_loss: 1.0204 - val_acc: 0.5422\n",
      "Epoch 12/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8463 - acc: 0.6555 - val_loss: 1.0881 - val_acc: 0.5414\n",
      "Epoch 13/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8388 - acc: 0.6572 - val_loss: 1.0527 - val_acc: 0.5406\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "Epoch 14/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8302 - acc: 0.6583 - val_loss: 1.0913 - val_acc: 0.5472\n",
      "Epoch 15/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8230 - acc: 0.6591 - val_loss: 1.0421 - val_acc: 0.5438\n",
      "Epoch 16/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8146 - acc: 0.6599 - val_loss: 1.0502 - val_acc: 0.5446\n",
      "Epoch 17/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.8070 - acc: 0.6598 - val_loss: 1.1035 - val_acc: 0.5377\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "Epoch 18/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.7971 - acc: 0.6630 - val_loss: 1.1607 - val_acc: 0.5446\n",
      "Epoch 19/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.7906 - acc: 0.6643 - val_loss: 1.1129 - val_acc: 0.5403\n",
      "Epoch 20/20\n",
      "1516/1516 [==============================] - 12s 8ms/step - loss: 0.7824 - acc: 0.6667 - val_loss: 1.0797 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd6a5153c88>"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=20,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6h_RWqTXjMZX"
   },
   "source": [
    "# LSTM Final Model: Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UfXOHliiNzDT",
    "outputId": "d12fe2ec-9742-4ce2-ae12-4136ffd140d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8542419672012329, 0.5578611493110657]"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "batch_size_val = 14\n",
    "batches_per_epoch_val = 179\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aTIOkDgqbU2G"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IIK1izmmbgtU"
   },
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(model, x1_test_split, y1_test_split,\n",
    "                              display_labels=['negative', 'positive', 'mixed'],\n",
    "                              cmap=plt.cm.Blues,\n",
    "                              normalize='pred')\n",
    "disp.ax_.set_title('Confusion matrix for sentiment prediction on comments test data')\n",
    "\n",
    "print(disp.confusion_matrix)\n",
    "\n",
    "plt.savefig('accuracy.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT multi class sentiment prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
